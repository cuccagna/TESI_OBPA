\chapter*{Conclusioni}
\label{cap:con}

Questa tesi ha trattato le tematiche inerenti l'estrazione di conoscenza nell'ambito dell'Inferenza Grammaticale. 
 I metodi tradizionali tipicamente falliscono nel fornire una reale intuizione della natura dei dati, poichè i modelli consistono solo in una serie di parametri, incapaci di dare una umana comprensibile rappresentazione. \\
 Un approccio diametralmente opposto consiste nel rappresentare la conoscenza tramite una \textit{struttura} significativa per i campioni rifacendosi ai metodi dell'Algorithmic Learning Theory. Il modo di procedere di questi algoritmi detti di \textit{passive learning} consiste nella modellazione dello spazio dei concetti come nodi di un grafo e in una ricerca informata e guidata dai campioni a partire da una struttura sovradattata ai dati che conduce a scoprire delle nuove ipotesi che includono propriamente il concetto precedente e ne costituiscono una generalizzazione.  La tecnica duale a quest' ultima è l'\textit{active learning} che assume la conoscenza di un Oracolo in grado di risponde a \ac{MQ} ed \ac{EQ}.\\ Negli scenari reali come ad esempio \textit{model-based testing} e altre branche di \textit{formal-methods} il requisito di un Oracolo in grado di rispondere a \ac{EQ} è troppo stringente.\\
 Con l'intento di valicare questo limite sono stati realizzati varie versioni di un algoritmo denominato \ac{ObPA} che approssima la conoscenza dell'Oracolo e in ultima analisi l'\ac{EQ} tramite un classificatore costruito selezionandolo dal modello \ac{SVM} con un addestramento dell'insieme di campioni inizialmente noti.\\
L'algoritmo inizialmente proposto è stato potenziato tramite l'aggiunta di un \textit{kernel string} proposto in letteratura che da delle garanzie teoriche nell'ambito del \textit{PAC-learning}.  \\
Gli algoritmi sono stati sottoposti a una fase di sperimentazione su due dataset uno più semplice e un altro paragonabile per la complessità  degli elementi a quelli presenti in uno scenario reale; mediante il primo dataset si è dimostrata la correttezza degli algoritmi ottenendo anche degli ottimi risultati mentre sul secondo dataset l'algoritmo e in particolare la fase cruciale di addestramento del classificatore ha dimostrato che oltre una certa soglia di complessità nella maggior parte dei casi diventa poco efficace nonostante le promesse teoriche  dell'algoritmo di selection model implementato.\\
A causa dell'onerosità computazionale di alcune funzioni di libreria interne ed esterne a GI-Learning la fase di sperimentazione è stata ardua e non è stato possibile testare i limiti dell'algoritmo al massimo delle sue potenzialità. Per consentire di aumentare considerevolmente la dimensione del \textit{training set}  si potrebbe usare $\ac{SVM}^{perfct}$ che promette risultati equivalenti ad $\ac{SVM}^{light}$ ma prestazioni notevolmente migliori. Inoltre la libreria \ac{SVM} scelta non consente l'implementazione di \textit{hard margin}  simulato fissando il parametro trade-off C ad 1, si potrebbe pensare di fare una ricerca del migliore valore di C in connubio con 5-fold-validation o usare una libreria alternativa che implementi l'\textit{hard margin}.  Inoltre per uniformare l'algoritmo alle impostazione delle varie competizioni d'Inferenza Grammaticale come ZULU si potrebbe testare il comportamento dell'algoritmo approssimando soltanto le \ac{EQ} ed assumendo di potere effettuare \ac{MQ} esatte.\\
Un altro miglioramento alle prestazioni  potrebbe riguardare la sostituzione del W-Method che ha dato tanti problemi in fase di sperimentazione con i più efficienti Wp-Method e HSI.
 Infine \ac{ObPA} esula per ciò che concerne il funzionamento dal particolare algoritmo di \textit{active learning} e in questa sede si è scelto come si è detto \ac{ObP} perchè è uno dei più efficienti, ma nell'ottica di incrementare le prestazioni di \ac{ObPA} lo si può sostituire per sviluppi futuri con il più performante e recente  TTT algorithm \cite{SteffenTTT14}. 

