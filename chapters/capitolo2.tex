%!TEX encoding = UTF-8 Unicode
%!TEX root = ./../main.tex
%!TEX TS-program = xelatex

\chapter{Inferenza Grammaticale} % Second chapter title
\label{cap:due}

L' \ac{GI} è considerata una branca del \textit{machine learning} sebbene il primo algoritmo di \ac{GI} sia più datato della nascita del concetto di machine learning. Più in dettaglio \ac{GI} è un'istanza dell'inferenza induttiva e in particolare dell'apprendimento per induzione da esempi introdotti in \ref{sub:tipiapp}, e può quindi essere descritto come il problema di congetturare un linguaggio target sconosciuto  a partire da un \textit{training set} che di solito comprende un insieme finito di stringhe $S^{+}$ appartenenti ad un \ac{L} ,definite su un alfabeto $\Sigma$, dette positive ed eventualmente anche un insieme finito di stringhe negative $S^{-}$ che non appartengono ad \ac{L}.

Sebbene il nome \textit{inferenza grammaticale} potrebbe suggerire che l'\textit{output} di un algoritmo d'\textit{inferenza grammaticale} sia una grammatica non è questo il caso --- qualsiasi altra descrizione di un linguaggio come un automa, un'espressione regolare, ecc. può essere pure usata. In questa tesi l'attenzione è volta agli algoritmi di \ac{GI} il cui \textit{linguaggio target}  appartiene alla classe più semplice della gerarchia di Chomsky: i linguaggi regolari. In quest ultimo caso si suole parlare di \textbf{inferenza grammaticale regolare} e talvolta di \textbf{inferenza induttiva regolare} (\ac{IIR}).

\section{Connotare l'IIR}
Una caratterizzazione del \textit{learning da esempi}  induttivo  ,seguendo \cite{Mic86a}, è stata già fornita in \ref{sub:appindes}. In questa sede è opportuno puntualizzare ed approfondire alcuni dei punti di cui si compone e soprattutto contestualizzarla all'\ac{IIR} dato che la classificazione in \ref{sub:appindes} fa riferimento all'apprendimento generico di un concetto e nell'\ac{IIR} si specializza l'oggetto dell'inferenza che diventa un linguaggio regolare.  I punti di cui si compone sono\footnote{Da adesso in poi e per tutto il resto della tesi ci si discosterà dalla definizione di consistenza di Mychalski esposta in \ref{sub:appindes} a meno che non venga espressamente indicato. Con consistenza si intenderà che, dato un \ac{DFA} $A$ e un insieme di istanze $S=S^{+} \cup S^{-} \,\, \forall x \in S^{+} :   \lambda^{A}(x)=1 \land \forall x \in S^{-} :   \lambda^{A}(x)=0$ }:

\begin{description}
\item[Spazio delle istanze]L’algoritmo inferenziale
induttivo riceve in ingresso degli esempi (ed eventualmente anche controesempi),di membri del concetto target(specifiche istanze) , sottoinsieme dello spazio delle istanze che costituisce l’insieme di tutte le possibili istanze osservabili. Nell'\ac{IIR} le istanze sono delle stringhe definite sull'alfabeto $\Sigma$. 
\item[Spazio dei concetti]E' l'insieme di tutte le possibili soluzioni e nell'\ac{IIR} rappresenta l'insieme dei linguaggi regolari.
\item[Spazio delle descrizioni]Costituisce lo spazio che contiene le descrizioni operative degli elementi dello spazio dei concetti. Nell'\ac{IIR} si possono usare le espressioni regolari, gli \textit{NFA} o i \ac{DFA} anche se di norma si usano i \ac{DFA} perchè è garantita l'esistenza di un \ac{DFA} canonico.
\item[Spazio delle ipotesi]Lo spazio delle ipotesi contiene quei concetti consistenti con gli esempi osservati ed è quindi un sottoinsieme dello spazio dei concetti.
\item[Criteri di successo]Sono i criteri che permettono di decretare che il processo d'inferenza è concluso. Esistono varie tecniche e varianti ma i due metodi principali sono:
\begin{itemize}
\item{\textit{Identification in the limit}}
\item{\textit{PAC-learning}}
\end{itemize}
\begin{definizione*}[Identification in the limit]Un linguaggio \ac{L} è identificato al limite da un algoritmo di inferenza  se ad un certo punto del processo inferenziale l' ipotesi intermedia $H$ generata è una descrizione di \ac{L} e da quel punto in poi $H$ non muta al variare delle istanze presentate in ingresso all'algoritmo.
\end{definizione*}
Si è supposto che le istanze presentate in ingresso ad ogni iterazione dell'algoritmo di inferenza siano crescenti e includenti le istanze contenute alle iterazioni precedenti, e che le istanze possano divenire anche infinite. Allora si ha identificazione al limite \cite{Gold67} se a partitire da una determinata iterazione dell'algoritmo induttivo \ac{H} resta invariata. \\
Nel \textit{PAC-learning} \cite{Val84} invece si richiede una identificazione solo parziale e probabilistica di \ac{L}. Sia \ac{L} il target e \ac{H} l'ipotesi induttiva generata da un algoritmo di \ac{IIR} . Sia $D$ una distribuzione di probabilità di tutte le stringhe su $\Sigma^{*}$ allora si ha la seguente definizione:
\begin{definizione*}[True error]Il \textbf{\textit{tasso di errore}} o \textbf{\textit{true error}} $error_{D}(H)$ di \ac{H} rispetto alla distribuzione  $D$ e ad \ac{L} è
\begin{equation*}
    error_{D}(H) = \sum_{x \in \ac{L} \oplus L(\ac{H})}^{}D(x)
\end{equation*}
\end{definizione*}
Informalmente il \textit{true error} è la probabilità che una stringa estratta casualmente dallo spazio delle istanze --- in accordo alla distribuzione di probabilità $D$ --- appartenga allo spazio dove \ac{H} ed \ac{L} differiscono . L'algoritmo induttivo nel \textit{PAC-learning} prende due parametri in ingresso l'accuratezza $\epsilon$ e la confidenza $\delta$ entro cui operare.

\begin{definizione}[PAC learning]\label{def:PacL}Una classe di linguaggi $\mathbb{L}$ è \textbf{PAC-learnable} se esiste un algoritmo $A$ tale che $\forall L \in \mathbb{L}$, per ogni distribuzione $D$ su $\Sigma^{*} \text{,} \forall \epsilon(0<\epsilon<1) \text{,} \forall \delta(0<\delta<1), A$ su istanze fornite in accordo alla distribuzione $D$ produce con probabilità $1-\delta$ un'ipotesi \ac{H} tale che $error_{D}(H) \leq \epsilon$.
\end{definizione}
\end{description}

E' possibile trovare una caratterizzazione alternativa ma analoga del problema induttivo rispetto a quella data in \cite{Angluin83} in cui si effettua una classificazione anche in base a come sono presentate le istanze e al metodo impiegato nello spazio di ricerca:
\begin{description}
\item[Presentazione delle istanze]Se l'insieme di istanze disponibili per l'algoritmo d'inferenza induttiva regolare, S , per apprendere una \ac{DFA}  target $A$ sono tali che $\forall x \in S \,\lambda^{A}(x) = 1$ si parla di \textbf{presentazione positiva} cioè tutti gli esempi(istanze) sono accettanti nel \ac{DFA} $A$. In questo caso si scrive $S=S^{+}$. Questo \textit{setting} è  denominato \textit{text learning}\cite[p. 217]{DeLaHiguera10}. Si parla invece di \textbf{presentazione completa} quando $S=S^{+} \cup S^{-}$ cioè esistono sia esempi accettanti che rigettanti in simboli $\exists x \in S :   \lambda^{A}(x)=1 \land \exists x \in S :   \lambda^{A}(x)=0$. Quest ultimo caso è menzionato come \textit{informed learning} \cite[p. 237]{DeLaHiguera10} .\\

Si effettua un'ulteriore suddivisione del tipo di presentazione in base a come gli esempi vengono presentati all'algoritmo d'inferenza:
\begin{itemize}
\item \textbf{Presentazione Given-Data}\\Le istanze sono un insieme finito presentate totalmente fin dall'inizio del processo.
\item \textbf{Presentazione completa}\\Le istanze (positive o complete) sono una sequenza infinita e sono presentate in successione (in maniera incrementale).  
\item Esiste un \textbf{\textit{Oracolo}} che è in grado di rispondere a delle \textit{membership query} ed \textit{equivalence query} ed è la macchina inferenziale che direttamente interroga attivamente l'\textit{Oracolo}. Questa modalità sarà approfondita nel capitolo \ref{sec:acl}.
\end{itemize}
\item[Metodo inferenziale]Gli algoritmi di \ac{GI} e di \ac{IIR} si possono ricondurre a dei problemi di ricerca in un grafo in cui ogni nodo è un'astrazione che rappresenta uno dei possibili linguaggi dello spazio dei concetti. \ac{L} ,cioè il target, è da ricercare in questo spazio.  Allora con algoritmo d'inferenza \textit{astratto} si intende un algoritmo che ha valenza solo teorica perchè una effettiva realizzazione sarebbe troppo onerosa computazionalmente. Il più importante di questi algoritmi è l'algoritmo di \textit{induzione per numerazione} per il quale esiste la seguente congettura largamente condivisa:

\begin{teorema*}La classe dei linguaggi ricorsivi identificabili al limite da un algoritmo di inferenza grammaticale , è anche identificabile al limite da un algoritmo di induzione per numerazione
\end{teorema*} 
 L'induzione per numerazione cerca ad ogni iterazione dell'algoritmo tra le descrizioni di tutti i concetti consistenti con gli esempi in ingresso e ne sceglie uno secondo qualche criterio di preferenza. Tali descrizioni sono tipicamente un insieme di cardinalità infinita e ciò rende questo metodo impraticabile.\\
 Per algoritmi induttivi \textit{concreti} si intende invece quegli algoritmi efficientemente implementabili. Tra questi possiamo distinguere tra:
 \begin{itemize}
 \item \textbf{Algoritmi esaustivi}\\
 Sono algoritmi deterministici che sotto opportune condizioni degli esempi d'ingresso garantiscono di trovare il linguaggio target
 \item \textbf{Algoritmi euristici}\\
 Si tralascia di seguire dei percorsi di ricerca nel grafo per aumentare l'efficienza ,di solito a scapito della perdita della garanzia di successo. Tipicamente si usano dei meccanismi aleatori, come nel caso degli algoritmi genetici che manipolano delle informazioni simboliche attraverso dei processi aleatori numerici.
 \end{itemize}  
\end{description}

\section{Limiti dell' IIR}
\label{sec:limIIR}
Uno dei problemi dell'\ac{GI} e di \ac{IIR} è che nessun sottoinsieme finito di un insieme infinito ha informazioni sufficienti che gli consentono di inferire con assoluta certezza a quale insieme il sottoinsieme appartiene. Nella fattispecie ,dato un insieme finito di stringhe $S$,  appartenente a un linguaggio infinito \ac{L} , non si può inferire \ac{L} da $S$ con assoluta certezza. Il motivo è che $S$ è un sottoinsieme di molti altri, tipicamente infiniti, linguaggi diversi da \ac{L}. Questo problema è stato trattato da Gold in \cite{Gold67} nel paradigma dell'\textit{identification in the limit} ottenendo i seguenti risultati:
\begin{teorema}
La classe dei linguaggi superfiniti non può essere identificata al limite attraverso una presentazione positiva di esempi.
\end{teorema}
Ne consegue che i linguaggi regolari di cui i linguaggi superfiniti sono un sottoinsieme non sono parimenti identificabili al limite solo tramite esempi positivi. Considerando anche gli esempi negativi il seguente teorema sempre in  \cite{Gold67}  stabilisce il limite alla classe di linguaggi inferibili:
\begin{teorema}
Non è possibile inferire l'intera classe dei linguaggi ricorsivi attraverso una presentazione completa degli esempi.
\end{teorema}
Invece i linguaggi primitivi ricorsivi e quindi anche i linguaggi regolari che sono un sottoinsieme sono identificabili al limite come attesta il seguente risultato:
\begin{teorema}
La classe dei linguaggi primitivi ricorsivi è identificabile al limite mediante una presentazione completa degli esempi
\end{teorema}

Un altro risultato implicito che si evince dal lavoro di Gold è che non possiamo mai essere sicuri di apprendere il linguaggio corretto a meno che il numero di esempi non sia infinito. Con una presentazione finita l'unica cosa di cui possiamo essere certi è della consistenza della soluzione inferita con il \textit{training set} (la presentazione). Se il \textit{training set}  è grande aumenta la fiducia nell'approssimazione della soluzione inferita con il linguaggio target sconosciuto ma senza mai esserne certi e questa assunzione è nota come \textbf{Inductive Learning Hypothesis} \cite{Abela02}. Con il \textit{PAC-learning} si ottiene pure un'approssimazione del linguaggio target ma è possibile quantificare quanto vicini saranno la soluzione ottenuta ed il target e con quale probabilità.\\

Un altro problema che va affrontato è che tipicamente il numero di ipotesi consistenti  con gli esempi a disposizione è  infinito, quindi è necessario stabilire un \textbf{inductive preference bias} \cite{Abela02} cioè un criterio di preferenza da usare per selezionare quale delle congetture consistenti  rispetto ai dati scegliere. Nel caso dell'\ac{IIR}  l'\textit{inductive preference bias} che si adotta è il principio del \textbf{\textit{Rasoio di Occam}} che consiste nello scegliere sempre la soluzione più semplice che nell'\ac{IIR} significa scegliere il \ac{DFA} minimo\footnote{Si è soliti scegliere quasi sempre i \ac{DFA} come descrizione di un linguaggio regolare proprio perchè assicurano l'esistenza e l'unicità di un \ac{DFA} minimo}. Tale scelta da maggiori garanzie che il processo di generalizzazione abbia avuto luogo scongiurando il rischio di \textit{overfitting} cioè di un \ac{DFA} sovradattato agli esempi dati.

Il seguente risultato negativo è relativo a quest ultimo requisito di trovare il \ac{DFA} minimo:
\begin{teorema}
\label{teo:minhard}
Trovare il più piccolo automa finito deterministico consistente  rispetto a  un insieme di esempi completo è un problema NP-hard \cite{Gold78}.
\end{teorema}

\section{Passive learning}
 
Gli studi su \ac{GI} si possono suddivedere in due filoni, uno volto ad indagare i limiti teorici dell'apprendimento di linguaggi in determinati paradigmi ,come in \ref{sec:limIIR}, e l'altro volto a superare sotto opportune assunzioni i limiti teorici emersi rendendo gli algoritmi utilizzabili in termini di efficienza computazionale. Quest ultimo tema sarà affrontato adesso volgendo in particolare l'attenzione sugli algoritmi di \textbf{passive learning} e sulla strategia che li governa. La trattazione non sarà volutamente esaustiva dato che l'oggetto di studio di questo lavoro è l'\textit{active learning} che è una tecnica duale rispetto al \textit{passive learning}.

\subsection{Ricerca nel reticolo}
\label{sub:ricret}
I risultati negativi del teorema \ref{teo:minhard} sull'apprendimento del \ac{DFA} minimo possono essere superati delineando il problema di ricerca del  \ac{DFA} minimo come un problema di ricerca in un uno spazio degli stati in cui ogni stato è la modellazione di un \ac{DFA}. La strategia più semplice sarebbe quella enumerativa che ha come grafo di ricerca tutto lo spazio delle descrizioni e preleva da questo spazio l' ipotesi minima. Ma tale tecnica è impraticabile perchè tale spazio ha cardinalità infinita (basta pensare che solo i \ac{DFA} consistenti e completi con un dato \textit{training set} sono di per sè infiniti). Allora si definisce come grafo di ricerca il cosidetto \textbf{reticolo booleano} indicato con \textbf{$Lattice(PTA(S^+))$}che ha come nodo radice \textit{PTA$(S^+)$}. La radice può essere modellata come un insieme che comprende tutti gli stati dell'automa \textit{PTA$(S^+)$}, e l'operatore che consente di generare i nodi figli della radice (e  applicando ricorsivamente l'operatore anche ai figli ottenuti consente di derivare anche gli altri nodi) è una relazione d'ordine parziale  $\approx$ (cioè binaria transitiva,simmetrica e riflessiva) che applicata al \textit{PTA$(S^+)$} consente di derivare gli automi quoziente $PTA(S^+)/\!\!\approx$ che non sono altro che una fusione di alcuni degli stati del \ac{DFA} di partenza in base alla relazione d'ordine parziale definita. Inoltre l'automa quoziente $A/\!\!\approx$ ottenuto applicando la relazione $\approx$ sul nodo che è un automa $A$ è tale che $L(A) \subseteq L(A/\!\!\approx)$ quindi tutti gli automi ottenuti nel reticolo sono consistenti con $S^{+}$ ed estendendo il linguaggio da cui sono originati effettuano il processo induttivo generalizzando. Questa tecnica è detta di \textit{state-merging} in quanto ad ogni passo effettua una \textbf{fusione} degli stati dell'automa cui la relazione è applicata per ottenere un nuovo nodo e tutto il processo è noto in letteratura come \textbf{passive learning}.\\
Un aspetto che finora è stato trascurato riguarda se il \ac{DFA} minimo è sempre contenuto nel \textit{lattice}  altrimenti la procedura di ricerca potrebbe essere infruttuosa. Il seguente teorema \cite{Pao78} da una risposta affermativa se alcune condizioni sono verificate:

\begin{teorema}
Se l'insieme di istanze positive $S^{+}$ è strutturalmente completo rispetto al \ac{DFA} minimo target $M$ allora $M \in Lattice(PTA(S^{+}))$. 
\end{teorema}
laddove
\begin{definizione}[Insieme di esempi positivi strutturalmente completo]
\label{def:strcom}
Un insieme di esempi positivi $S^{+}$ è detto \textbf{strutturalmente completo} rispetto a un automa $M$ accettante $L$ se
\begin{itemize}
\item ogni stato di $\mathbb{F}_{\mathbb{A}}^{M}$ è impiegato da almeno una stringa di $S^{+}$
\item ogni transizione di $M$ è utilizzata nell'accettazione di almeno un esempio di $S^{+}$
\end{itemize}
\end{definizione}

Tuttavia la cardinalità del $Lattice(PTA(S^{+}))$ se $\norma{PTA(S^{+})} = n$ è :
\begin{equation*}
C_{n} = \sum_{i=0}^{n-1}\binom{n-1}{i}C_{i}  \quad \text{con } C_{0}=1
\end{equation*}
e rende impraticabile qualsiasi algoritmo di ricerca per enumerazione. Anche una ricerca in ampiezza è impraticabile. Inoltre  per avere la garanzia dell'automa minimo nel \textit{lattice} è necessario fare delle assunzioni, analogamente per effettuare una ricerca efficiente nel \textit{lattice} del \ac{DFA} minimo sarà necessario imporre dei vincoli.

\subsection{Algoritmi concreti} 
\label{sub:algcon}
 Qui si presentano le peculiarità dei due principali algoritmi di \textit{passive learning} in uno scenario di \textit{informed learning}. La trattazione ivi esposta è qualitativa e di alto livello ed i dettagli implementativi sono tralasciati.
 \subsubsection{Red-Blue Framework}
 \label{subsub:rbf}
 Questo framework riduce significativamente il numero di possibili \textit{merge} tra stati senza ridurre il numero di possibili soluzioni. Gli algoritmi con questo \textit{setting} mantengono un cuore di stati \textit{red} e una frontiera di stati \textit{blue} che sono gli stati immediatamente raggiungibili (figli diretti) a partire dagli stati \textit{red}. Un algoritmo di \textit{red-blue state-merging} esegue \textit{merges} solo tra stati \textit{blue} e stati \textit{red} e se non sono possibili \textit{red-blue merges} l'algoritmo \textbf{\textit{promuove}} uno stato \textit{blue} a \textit{red}. Gli stati \textit{red} inoltre sono gli stati del \ac{DFA} target che sono già stati identificati.
L'idea è stata descritta per la prima volta in \cite{Abbadingo98} in cui una prima versione dell'algoritmo \textit{EDSM}--- che valuta il \textit{merge} tra tutte le coppie di stati dell' ipotesi corrente \cite[p. 6]{Abbadingo98} ---  è migliorata nel \textit{Blue-fringe Algorithm} che secondo il principio di blanda località summenzionato valuta il merge solo tra stati di colore \textit{red} e \textit{blue}.\\
Sebbene la nomenclatura \textit{red-blue framework} non venga ufficialmente introdotta in \cite{Abbadingo98} con questo nome, è adottata in molti autorevoli testi e conferenze di riferimento su \ac{GI} come \cite{DeLaHiguera10} e  \cite[p. 70] {RBF10}.

\subsubsection{RPNI}
L'algoritmo \textit{ REGULAR POSITIVE  AND NEGATIVE INFERENCE} (RPNI) \cite{Oncina92} è uno dei più noti algoritmi di \textit{state-merging} che consente di trovare un \ac{DFA} --- in uno scenario di \textit{informed learning} --- consistente e completo con gli esempi $S = S^{+} \cup S^{-}$ in tempo polinomiale. E' un algoritmo esaustivo  che supera il problema della dimensionalità del reticolo booleano eseguendo una ricerca in profondità con backtracking a partire dal $PTA(S^{+})$ guidata dagli esempi negativi.\\
Se S è caratteristico per \ac{L} allora RPNI assicura che venga trovato il \ac{DFA} minimo:
\begin{definizione}[Insieme caratteristico]
\label{def:car}
 Un insieme di esempi completo $S = S^{+} \cup S^{-}$ è \textbf{caratteristico} per un linguaggio $L$ se:
\begin{itemize}
\item $S^{+}$ è \textit{strutturalmente completo} (definizione \ref{def:strcom})  per il \ac{DFA} che accetta $L$
\item  $S^{-}$ impedisce il \textit{merge} di due stati $p,q \text{ di un } \ac{DFA} \in Lattice(PTA(S^{+})) \text{tali che } p \not\equiv q$ durante un'esplorazione del lattice.
\end{itemize}
\end{definizione}
Se viene a mancare la condizione in \ref{def:car} di insieme caratteristico non è assicurata la terminazione con il \ac{DFA} minimo ma è comunque garantito un \ac{DFA} consistente rispetto agli \textit{esempi nel training set} grazie alla proprietà d'inclusione descritta  in \ref{sub:ricret}.

Il funzionamento a grandi linee di RPNI è:
\begin{enumerate}
\item Costruire $PTA(S^{+})$, numerare gli stati in base all'ordine lessicografico delle stringhe di $S^{+}$ e inizializzare l'insieme degli stati \textit{red} con lo stato corrispondente a $\epsilon$ e gli stati \textit{blue} con i suoi figli diretti.

\item Per ogni stato \textit{blue} si effettua sul \ac{DFA} corrente (inizialmente è $PTA(S^{+})$)il \textit{merge} con ogni stato \textit{red} estraendo gli stati in ordine lessicografico ottenendo un \ac{DFA} temporaneo $A$.
\begin{enumerate}
\item Se $A[S^{-}] \not\in \mathbb{F}_{\mathbb{A}}^{A}$ il \textit{merge} è valido, i restanti \textit{merge} dello stato \textit{blue} corrente con gli altri eventuali stati \textit{red} non vengono valutati, ed $A$ è il nuovo automa da considerare.
\item Se per il corrente stato \textit{blue} non si trova nessun \textit{merge} compatibile (con nessuno dei nodi \textit{red}), si esegue la sua \textit{promozione} a nodo \textit{red} e gli stati che sono figli diretti di questo nuovo nodo \textit{red} sono aggiunti ai nodi \textit{blue}
\end{enumerate}
\item Torna al punto 2 fin quando l'insieme degli stati \textit{blue} non è vuoto.
\end{enumerate}

Questa procedura può generare condizioni di non-determinismo cioè gli automi intermedi e finale prodotti possono essere degli NFA, per ovviare a questo inconveniente si può rendere il \textit{merge} una procedura ricorsiva che oltre a fondere gli stati rossi e blu effettua eventualmente delle ulteriori fusioni se la condizione di determinismo dell'automa creato dal corrente \textit{merge} non è posseduta. Vedasi \cite{DeLaHiguera10} per una versione di RPNI che genera sempre \ac{DFA}.
Infine il costo computazionale dell'algoritmo nella sua versione originale \cite{Oncina92} è $\mathcal{O}( (\norma{S^{+}}+\norma{S^{-}})\norma{S^{+}}^{2} )$

\subsubsection{EDSM}
\textit{EVIDENCE DRIVE STATE MERGING}  è un algoritmo di \textit{state-merging} \textit{euristico} che come RPNI non garantisce di trovare un \ac{DFA} canonico ma solo una soluzione ottima a meno che il \textit{training set} non sia caratteristico \ref{def:car}. L'algoritmo nella sua versione base è presentato in \cite{Abbadingo98} ed esistono delle versioni più efficienti come \textit{Blue-fringe EDSM} sempre in \cite{Abbadingo98} che usando il \textit{red-blue framework} limitano notevolemente il numero dei \textit{merge} e ne incrementano le \textit{performances}, ed è questo ultimo che viene brevemente spiegato qui.
Il miglioramento rispetto a RPNI è che EDSM non è \textit{greedy} nell'esecuzione dei \textit{merges} ma valuta tutti i merges possibili tra stati \textit{red} e \textit{blue} ---invece RPNI selezionerebbe il primo possibile e ignorerebbe gli altri \textit{merges} --- e si sceglie il \textit{merge} migliore in base ad un'euristica. La migliore euristica emersa nella competizione Abbandingo è quella di Price che valuta un \textit{merge} non possibile se almeno una stringa accettante e almeno una rigettante rispettivamente di $S^{+} \text{ e } S^{-}$ terminano nello stesso stato , ed ha invece un punteggio tanto più alto quante più stringhe di $S^{+}$ \text{ o di } $S^{-}$ (ma non di entrambi gli insiemi, quindi l'\textit{or} è esclusivo)  terminano in uno stesso stato del \ac{DFA} \textit{mergiato} che si sta valutando. Si sceglierà il \ac{DFA} col punteggio maggiore.\\
Un'altra differenza sostanziale rispetto a RPNI in EDSM è la priorità data alle \textit{promozioni} a scapito di possibili fusioni: il \textit{merge} viene effettuato soltanto se tutti i possibili \textit{merges} tra tutte le coppie di stati \textit{red} e \textit{blue} è possibile secondo l'euristica, altrimenti si privilegia la \textit{promozione} dello stato \textit{blue} a \textit{red}. 
EDSM costituisce lo stato dell'arte per ciò che riguarda gli algoritmi di \textit{passive learning}.


\section{Active Learning}
\label{sec:acl}
L' \textit{Active Learning} è un caso speciale di \textit{semi-supervisionato machine learning}\footnote{Nel semi-supervisionato learning una piccola quantità di dati è etichettata e la restante, la maggioranza, è senza etichetta.} in cui un algoritmo di \textit{learning} può interagire con l'utente o  qualche sorgente d'informazione per ottenere informazioni significative come ad esempio l'etichetta di un'istanza. Nel contesto dell' \ac{IIR} l' \textit{active learning} non esplora il reticolo costruito a partire dal PTA o dall' APTA come fanno gli algoritmi presentati in \ref{sub:algcon}  ma si basa su una stretta interazione tra il \textit{\textbf{learner}} e il \textit{\textbf{teacher}}  detto anche \textit{\textbf{Oracolo}} o \textit{\textbf{informant}}. L' \textit{active learning} è una tecnica duale rispetto al \textit{passive learning}: il \textit{passive learning} è un approccio \textit{top-down} che esplora lo spazio di ricerca a partire dal nodo iniziale (PTA o APTA costruito  dagli esempi iniziali) e tramite dei \textit{merges} genera nuovi nodi e nel caso degenere ha come ultimo nodo l'automa universale, invece l'\textit{active learning} effettua una ricerca \textit{bottom-up} che inizia dall'automa universale e mediante lo \textbf{\textit{split}} degli stati raffina l'ipotesi. Inoltre è il \textit{learner} che sceglie attivamente gli esempi e  il \textit{teacher} può selezionare attentamente i controesempi significativi: proprio per queste ragioni spesso il numero di esempi per apprendere un concetto e in generale il tempo di esecuzione del processo di apprendimento è minore negli algoritmi di \textit{active learning} che in quelli di \textit{passive learning}.   
L'\textit{active learning} nasce per ragioni teoriche come ad esempio per dimostrare che non è possibile apprendere in maniera efficiente alcune classi di linguaggi con una presentazione given-data: nell' \textit{active learning} nel cui contesto è il \textit{learner} che seleziona gli esempi  è sufficiente dimostrare che il numero di query non può essere polinomiale . Ma è anche applicabile in numerosi contesti pratici come la Robotica in cui un agente può costruire una mappa usando l'interazione tra i sensori e l'ambiente come \textit{Oracolo} o nella modellazione dell'acquisizione dei linguaggi naturali dove attribuire la figura del \textit{teacher} al genitore risulta naturale. Qui si esaminerà l' \textit{active learning} nell' \ac{IIR}. L* è senz altro il più noto algoritmo  di \textit{active learning} applicato ai linguaggi regolari. Il più recente e performante \textit{Observation Pack} sarà introdotto nel capitolo \ref{cap:quattro}
\subsection{Active learning nell' Inferenza Induttiva Regolare}
Il paradigma dell' \textit{active learning} si basa sull'esistenza di un \textit{Oracolo} che conosce \ac{L} e può rispondere solo a certi tipi di interrogativi sottopostigli dal \textit{learner}. L' \textit{Oracolo} può trovarsi in una situazione in cui più risposte valide sono possibili e in questo caso si deve assumere che non viene rispettata nessuna distribuzione di probabilità nelle risposte date ma che queste sono casuali pertanto nell'analisi dell'algoritmo si deve assumere il caso peggiore cioè un \textit{Oracolo} avverso (nell' algoritmo adoperato nell' \ac{IIR}, il table-filling descritto nella sottosezione \ref{sub:tea}, l'\textit{Oracolo} non garantisce di ritornare la \textit{\textbf{witness}} cioè il controesempio più breve).
I principali tipi di interrogativi possibili a cui si può sottoporre un \textit{Oracolo} sono:
\begin{itemize}
\item \textbf{\ac{MQ}} Una membership query è effettuata proponendo una stringa all'\textit{Oracolo}, che risponde YES se la stringa appartiene a \ac{L} e NO se la stringa non appartiene:\\\\
\centerline{$\text{\ac{MQ}} : \Sigma^{*}  \to \text{\{YES,NO\}}$}

\item \textbf{\ac{EQ}} (forte) Un'equivalence query (forte) è effettuata proponendo un \ac{DFA} ipotesi \ac{H} all'\textit{Oracolo} che risponde YES se il DFA ipotesi \ac{H} è equivalente al \ac{DFA} target altrimenti ritorna una stringa(\textit{witness}) appartenente alla differenza simmetrica tra \ac{L} e $L$(\ac{H}):\\\\
\centerline{\ac{EQ} : \textit{DFA}$ \,\to \text{\{YES\}} \cup \Sigma^{*}$}

\item \textit{\textbf{WEQ}} (debole) Un'equivalence query (debole) è effettuata proponendo un \ac{DFA} ipotesi \ac{H} all'\textit{Oracolo} che risponde YES se il DFA ipotesi \ac{H} è equivalente al DFA target altrimenti ritorna NO :\\\\
\centerline{\textit{WEQ} : \textit{DFA}$ \to  \text{\{YES,NO\}}$}

\item \textit{\textbf{SSQ}} Una subset query è effettuata proponendo un DFA ipotesi \ac{H} all'\textit{Oracolo} che risponde YES se $L$(\ac{H}) è un sottoinsieme di \ac{L} altrimenti ritorna una stringa appartenente a $L$(\ac{H}) che non appartiene ad \ac{L} :\\\\
\centerline{\textit{SSQ} : \textit{DFA}$ \to \text{\{YES\}} \cup \Sigma^{*}$}
\end{itemize}



I seguenti risultati e definizioni sono in \cite{Angluin90}.Si da la seguente definizione preliminare:
\begin{definizione}
Chiamiamo $\rho$ un'esecuzione del \textit{learner} A. Chiamiamo $\Braket{r_1,r_2,\dots r_m}$ la sequenza di risposte alle query $\Braket{q_1,q_2,\dots q_m}$ che l'\textit{Oracolo} fa durante l'esecuzione $\rho$ . Si dice che \textbf{A} è \textbf{polinomialmente  limitato} se esiste un polinomio a due variabili p() che dato qualsiasi formalismo L descrivente  \ac{L} e in qualsiasi esecuzione $\rho$, e a qualsiasi \textit{query point}(indica il momento prima che avvenga una query ed è definito come un numero intero che specifica il numero di query avvenute fino a quel momento) $k$ dell'esecuzione, denotando il tempo di esecuzione prima di quel punto con $t_k$, si ha:
\begin{itemize}
\item $k \le p(\norma{L} , \text{max}\{\abs{r_i} : i \textless k \})$
\item $\abs{q_k} \le p(\norma{L} , \text{max}\{\abs{r_i} : i \textless k \})$
\item $t_k \in \mathcal{O}(p(\norma{L} , \text{max}\{\abs{r_i} : i \textless k \}))$
\end{itemize}
\end{definizione}
Informalmente significa che in qualsiasi \textit{query point k} di qualunque esecuzione, al momento precedente l'effettuazione della query $q_k$, si ha che il numero di query fatte, il tempo di esecuzione e la dimensione della prossima query ($q_k$) sono tutte limitate da un polinomio $p$ dipendente dalla dimensione del target e dalla lunghezza del più lungo controesempio ritornato dall'\textit{Oracolo} fino a quel punto
   
La seguente definizione stabilisce quando una classe di linguaggi è efficientemente \textit{identificabile in the limit} da un algoritmo di  \textit{learning}. 
\begin{definizione}
\label{def:pol}
Una classe di linguaggi $\mathfrak{L}$ è \textbf{polinomialmente \textit{identificabile in the limit con query}} fissati i tipi di query possibili se esiste un \textbf{polinomialmente limitato} \textit{learner} \textbf{A} che dato il formalismo descrivente qualsiasi linguaggio $L \in  \mathfrak{L}$, identifica L in the limit, cioè ritorna  L' equivalente ad L e termina.
\end{definizione}

Adesso ci si chiede se la classe dei linguaggi regolari è polinomialmente identificabile in the limit tramite qualche algoritmo di apprendimento secondo la definizione \ref{def:pol}. E' importante sottolineare che la risposta a questa domanda dipende anche dalla classe cui appartiene l'\textit{Oracolo} cioè dal tipo di interrogativi che è possibile rivolgergli.  A tal proposito si hanno i seguenti risultati :
\begin{teorema}
\label{teo:noi}
La classe dei linguaggi regolari  non è polinomialmente identificabile in the limit da un numero polinomiale di \ac{MQ}, \textit{WEQ} e \textit{SSQ}
\end{teorema}
Quindi come conseguenza del teorema \ref{teo:noi}   la classe dei linguaggi regolari non è polinomialmente identificabile in the limit  neanche sottoponendo all'\textit{Oracolo} esclusivamente \ac{MQ} .

Un'ulteriore risultato è il seguente: 
\begin{teorema}
\label{teo:noe}
La classe dei linguaggi regolari (usando i \ac{DFA} come formalismo descrittivo)  non è polinomialmente identificabile in the limit da un numero polinomiale di \ac{EQ} (forti)
\end{teorema}
Si rimanda alla sezione \ref{sec:lstar} per le condizioni di polinomiale identificabilità in the limit dei linguaggi regolari
\section{L*}
\label{sec:lstar}
L* è il più noto algoritmo di \textit{active learning} nell'ambito dell' \ac{IIR} e garantisce di emettere in output il DFA minimo ( o uno ad esso isomorfo ) accettante \ac{L}. Detto n il numero degli stati del DFA target minimo ed m la lunghezza del più lungo controesempio ritornato dall' \textit{Oracolo} durante l'inferenza, il costo computazionale di L* sarà limitato da una funzione polinomiale di n ed m. In L* il \textit{teacher} appartiene alla classe dei \ac{MAT} in grado di rispondere ad \ac{EQ} e \ac{MQ}. Questi risultati ,che consentono di dire che i linguaggi regolari sono polinomialmente identificabili in the limit (definizione \ref{def:pol}),  sono stati conseguiti da Dana Angluin \cite{Angluin87} e succintamente riportati nel seguente teorema:
\begin{teorema}
Dato un \ac{MAT}  presentante un linguaggio regolare sconosciuto U, il Learner L* termina restituendo in output un automa finito isomorfo al DFA minimo accettante  il linguaggio target U. Inoltre, se n è il numero di stati del DFA minimo accettante U e  m è un limite superiore della lunghezza di ogni controesempio ritornato dal Teacher, allora il costo totale di esecuzione di L* è limitato da un polinomio in n ed m 
\end{teorema}

L* viene presentato all'interno del \textit{red--blue framework} (introdotto in \ref{sub:algcon}) che in algoritmi come \textit{EDSM} (vedasi sottosezione \ref{sub:algcon}) consente di diminuire i \textit{merges}. In L* l'adozione di questo \textit{framework} malgrado non comporti un vantaggio computazionale consente un'esposizione più chiara.  
\subsection{Tabella di Osservazione}
\label{sub:obt}
Una \textbf{tabella di osservazione} è una struttura dati che rappresenta il DFA ipotesi congetturato al passo corrente. Al suo interno sono codificati gli esiti delle \ac{MQ} richieste al \textit{teacher}.

\begin{definizione*}[Tabella di Osservazione] La \textit{tabella di osservazione} è una tripla $\Braket{STA, EXP, OT}$, dove:
\begin{itemize}
\item $\text{STA}=\text{RED} \cup \text{BLUE}$.  STA è un insieme finito di stringhe definite su $\Sigma$ che rappresentano gli stati. STA è \textbf{prefix--closed}\\
RED $\in \Sigma^{*}$ è un insieme finito di stati\\
$\text{BLUE} = \{ua \notin \text{RED} : u \in \text{RED}\}$ è l'insieme dei successori degli stati RED che non sono RED. Rappresentano le transizioni.
\item EXP $\in \Sigma^{*}$  è l'insieme degli esperimenti. E' \textbf{suffix--closed}
\item $\text{OT} : \text{STA} \times \text{EXP} \to \text{\{0,1,*\}}$ è una funziona così definita:\\\\
\centerline{$
OT[u][e] = 
\begin{cases}
1
& \text{se $ue \in \ac{L}$} \\
0 & \text{se $ue \notin \ac{L}$}\\
* & \text{altrimenti}
\end{cases}
$}   
\end{itemize}
\end{definizione*} 
Dalla tabella di osservazione si costruisce una nuova ipotesi e la si sottopone al \textit{teacher}. Se l'ipotesi non è equivalente al \textit{DFA target} il \textit{teacher} torna un controesempio che sarà usato dal \textit{learner} per \textit{splittare} gli stati e modificare la tabella di osservazione per ottenere una nuova ipotesi cofacente al controesempio. Le \ac{MQ} permettono di riempire i buchi generati dall'introduzione di nuovi prefissi dal controesempio.  A partire dalla tabella di osservazione è possibile costruire un DFA ipotesi sole se questa gode di tre proprietà:\\

{\large\textbf{Completezza}}

La completezza garantisce che non ci siano comportamenti parzialmente (o totalmente) sconosciuti per prefissi presenti all'interno della tabella.
\begin{definizione*}[Tabella completa] Una tabella è completa se non ha \textit{buchi}. Un \textit{buco} in una tabella di osservazione è una coppia (u,e) tale che $OT[u][e] = *$.
\end{definizione*}
L'eventuale incompletezza può essere eliminata mediante \ac{MQ} al \textit{teacher}.\\

{\large\textbf{Chiusura}}

La chiusura (algoritmo \ref{alg:lstar-close}) assicura che ogni possibile stato raggiunto con una transizione sia presente tra gli stati finali dell'automa. Dato un elemento $s \in$ STA e gli \textit{n} esperimenti $e \in $ EXP si indica con row(s) la riga in OT indicizzata da s cioè $row(s)=OT[s][e_1] \cdot OT[s][e_2] \cdot \dots OT[s][e_n]$ . Gli stati dell'automa sono un sottoinsieme degli stati RED, quando una transizione da uno stato RED porta ad uno stato BLUE  si deve trovare uno stato RED equivalente a quello BLUE (vedasi algoritmo \ref{alg:lstar-buildautomaton}) (almeno secondo i suffissi trovati fino a quel momento) in modo che la transizione arrivi in questo stato RED(che è presente nell'automa ipotesi perchè gli stati RED trovati fanno parte del \ac{DFA} ipotesi a differenza di quelli BLUE).
\begin{definizione*}[Tabella chiusa] Una tabella è \textbf{chiusa} se $\forall u \in \text{BLUE}, \exists s\\ \in \text{RED} : \text{row(u)} = \text{row(s)}$
\end{definizione*}
Se la tabella di osservazione non fosse chiusa è possibile renderla tale mediante una (o più) \textbf{promozione}, cioè l'inserimento di \textbf{u} responsabile della non chiusura nei RED e $u \cdot \Sigma$ nei BLUE\\

{\large\textbf{Consistenza}}

La consistenza  (algoritmo \ref{alg:lstar-consistent}) impedisce situazioni di indeterminismo nel DFA, nella fattispecie che da uno stato dell'ipotesi per uno stesso simbolo dell'alfabeto si giunga in stati di arrivo diversi. Questa situazione è resa possibile dal fatto che l'algoritmo non impedisce di avere due stati RED $s_1$ ed $s_2$ tali che $\text{row}(s_1) = \text{row}(s_2)$ . 
\begin{definizione*}[Tabella consistente]Una tabella di osservazione è \textbf{consistente} se $\forall s_1,s_2 \in \text{RED} : \text{row}(s_1)=\text{row}(s_2)\implies\forall a \in \Sigma,\text{row}(s_1a)=\text{row}(s_2a)$
\end{definizione*} 

La definizione sopra significa che affinchè vi sia consistenza ogni coppia di stati equivalenti RED cioè di stati in RED con righe uguali deve restare equivalente in STA aggiungendo qualsiasi simbolo dell'alfabeto. 
Se la tabella di osservazione non fosse consistente è possibile renderla tale ampliando l'insieme EXP con la stringa ottenuta dalla concatenazione del simbolo dell'alfabeto e dall'esperimento che hanno generato l'inconsistenza. Ciò assicura che i due stati $s_1$ ed $s_2$ che prima erano equivalenti (e che quindi rappresentavano un unico stato nell'ipotesi) adesso non lo sono più perchè  $\text{row}(s_1) \neq \text{row}(s_2)$ e quindi sarà aggiunto un nuovo stato all'insieme RED cioè un nuovo stato all'ipotesi.

\begin{algorithm}
\caption{LSTAR-BUILDAUTOMATON}\label{alg:lstar-buildautomaton}
\begin{algorithmic}[1]
\Statex
\Input a closed and complete observation table $\Braket{\text{STA,EXP,OT}}$
\Output DFA $\Braket{\Sigma,Q,q_\epsilon,F_A,F_R,\delta}$
\State $Q \gets \{q_u : u \in \text{RED} \land \forall v < u \: \text{row}(v) \ne \text{row}(u)\}$
\LineComment{le stringhe più corte sono minori e per stringhe della stessa lunghezza si intendono minori quelle che lessicograficamente vengono prima}
\State $F_{\mathbb{A}} \gets \{q_u \in Q : \text{OT}[u][\epsilon] = 1\}$
\State $F_{\mathbb{R}} \gets \{q_u \in Q : \text{OT}[u][\epsilon] = 0\}$
\For{$q_u \in Q$}
     \For{$a \in \Sigma$} $\delta(q_u,a) \gets q_w \in Q : \text{row}(ua) = \text{row}(w)$
     \EndFor
\EndFor
\State \textbf{end for}
\State \Return{$\Braket{\Sigma,Q,q_\epsilon,F_A,F_R,\delta}$}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{LSTAR}\label{alg:lstar}
\begin{algorithmic}[1]
\Statex
\Input --
\Output DFA $\mathcal{A}$
\State \Call{LSTAR-INITIALISE}{}
\Repeat
     \While{$\Braket{\text{STA,EXP,OT}} \textit{is not closed or not consistent}$}
          \If{$\Braket{\text{STA,EXP,OT}} \textit{is not closed}$}
          \vspace{0.5mm}
               \State $\Braket{\text{STA,EXP,OT}} \gets \Call{LSTAR-CLOSE}{\Braket{\text{STA,EXP,OT}}} $
          \EndIf
          \If{$\Braket{\text{STA,EXP,OT}} \textit{is not consistent}$}
          \vspace{0.5mm}
               \State $\Braket{\text{STA,EXP,OT}} \gets \Call{LSTAR-CONSISTENT}{\Braket{\text{STA,EXP,OT}}} $ 
          \EndIf    
     \EndWhile
     \State \textbf{end while}
     \State $\text{Answer} \gets \Call{EQ}{\Braket{\text{STA,EXP,OT}}}$
     \If{$\text{Answer} \ne \text{YES}$}
          \vspace{0.25mm}
          \State $\Braket{\text{STA,EXP,OT}} \gets \Call{LSTAR-USEEQ}{\Braket{\text{STA,EXP,OT}},\text{Answer}}$
     \EndIf
\Until{$\text{Answer} = \text{YES}$}
\State \textbf{return} \Call{LSTAR-BUILDAUTOMATON}{$\Braket{\text{STA,EXP,OT}}$}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{LSTAR-INITIALISE}\label{alg:lstar-initialise}
\begin{algorithmic}[1]
\Statex
\Input --
\Output $\Braket{\text{STA,EXP,OT}}$
\State $\text{RED} \gets \{q_\epsilon\}$
\State $\text{BLUE} \gets \{q_a : a \in \Sigma\}$
\State $\text{EXP} \gets \{\epsilon\}$
\State $\text{OT}[\epsilon][\epsilon] \gets \Call{MQ}{\epsilon}$
\vspace{1mm}
\For{$a \in \Sigma$} $\text{OT}[a][\epsilon] \gets \Call{MQ}{a}$
\EndFor
\State \textbf{return} $\Braket{\text{STA,EXP,OT}}$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{LSTAR-CLOSE}\label{alg:lstar-close}
\begin{algorithmic}[1]
\Statex
\Input $\Braket{\text{STA,EXP,OT}}$
\Output $\Braket{\text{STA,EXP,OT}}$ updated
\For{$s \in \text{BLUE} \: \textit{such that} \: \forall u \in \text{RED} \: \text{row}(s) \ne \text{row}(u)$}
\LineComment{Non per $\forall s$ ma per uno solo quindi la tabella in output può ancora essere non chiusa}
     \State $\text{RED} \gets \text{RED} \cup \{s\}$
     \State $\text{BLUE} \gets \text{BLUE} \: \setminus \: \{s\}$
     \For{$a \in \Sigma$} BLUE $\gets \text{BLUE} \cup \{s\cdot a\}$
     \EndFor
     \For{$u, e \in \Sigma^{*}  \: \textit{such that} \: \text{OT}[u][e] \textit{is a hole}$} $\text{OT}[u][e] \gets \Call{MQ}{ue}$
\EndFor
\EndFor
\State \textbf{end for}
\State \textbf{return} $\Braket{\text{STA,EXP,OT}}$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{LSTAR-CONSISTENT}\label{alg:lstar-consistent}
\begin{algorithmic}[1]
\Statex
\Input $\Braket{\text{STA,EXP,OT}}$
\Output $\Braket{\text{STA,EXP,OT}}$ updated
\State find $s_1, s_2 \in$ RED, $a \in \Sigma$ and $e \in$ EXP \textit{such that} row$(s_1) = \text{row}(s_2)$ and
\State $\text{OT}[s_1 \cdot a][e] \ne \text{OT}[s_2 \cdot a][e]$
\LineComment{se $s_1a \: \text{ed} \: s_2a$ differiscono per più di un esperimento basta considerarne uno}
\State $\text{EXP} \gets \text{EXP} \cup \{a \cdot e\}$ 
\For{$u, e \in \Sigma^{*}  \: \textit{such that} \: \text{OT}[u][e] \textit{is a hole}$} $\text{OT}[u][e] \gets \Call{MQ}{ue}$
\EndFor
\State \textbf{return} $\Braket{\text{STA,EXP,OT}}$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{LSTAR-USEEQ}\label{alg:lstar-useeq}
\begin{algorithmic}[1]
\Statex
\Input $\Braket{\text{STA,EXP,OT}} \text{ ,  Answer}$
\Output $\Braket{\text{STA,EXP,OT}}$ updated
\For{$p \in \text{PREF(Answer)}$}
\Comment{Anche Answer fa parte dei prefissi}
     \State $\text{RED} \gets \text{RED} \cup \{p\}$
\Comment{Se un pref. è già in OT renderlo RED se non lo è}
     \For{$a \in \Sigma : pa \notin \text{PREF(Answer)}$} $\text{BLUE} \gets \text{BLUE} \cup \{pa\}$ 
     \EndFor 
\EndFor
\State \textbf{end for}
\For{$u, e \in \Sigma^{*}  \: \textit{such that} \: \text{OT}[u][e] \textit{is a hole}$} $\text{OT}[u][e] \gets \Call{MQ}{ue}$
\EndFor
\State \textbf{return} $\Braket{\text{STA,EXP,OT}}$
\end{algorithmic}
\end{algorithm}

\subsection{L'algoritmo}
\subsubsection{Funzionamento}La \textit{ratio} che ispira L* é il teorema \textit{Myhill-Nerode} (sezione \ref{teo:m-n}). Nella tabella di osservazione le righe RED,in realtà un sottoinsieme delle stringhe RED, corrispondono agli stati del DFA ipotesi e le colonne, l'insieme EXP, corrispondono alle stringhe rappresentanti i suffissi che distinguono coppie di stati distinti dell'ipotesi. I singoli stati sono etichettati dalle stringhe che portano dallo stato iniziale allo stato stesso. Lo stato iniziale è etichettato dalla stringa $\epsilon$. Per ogni stato $q$ l'etichetta della colonna (un esperimento) indica lo stato che potrebbe essere raggiunto a partire dallo stato $q$ dopo la lettura della stringa corrispondente all'etichetta dell'esperimento. Due stati sono considerati equivalenti se hanno le righe uguali nella tabella.

L'algoritmo inizia costruendo una tabella di osservazione corrispondente all'automa universale (algoritmo \ref{alg:lstar-initialise})
Una volta resa la tabella completa,chiusa e consistente viene estratta l'ipotesi corrispondente\footnote{La prima ipotesi fatta dal \textit{learner} non è sempre l'automa universale, ma dipende dall'esito delle \ac{MQ}} e viene effettuta un'\ac{EQ} dell'ipotesi al \textit{teacher}. In caso di risposta affermativa cioè di equivalenza il processo termina in quanto il \textit{learner} ha identificato un automa uguale o equivalente al \textit{target} (L* inferisce il DFA minimo, invece il \textit{target} potrebbe non essere un DFA minimo). In caso contrario sarà ritornato un controesempio che sarà usato per modificare la tabella di osservazione e quindi formulare una nuova ipotesi. L'algoritmo \ref{alg:lstar} chiarifica e approfondisce i passaggi summenzionati.

\subsubsection{Correttezza}
\label{sub:cor}
Per verificare che L* è corretto è sufficiente dimostare che termina dato che la terminazione con un  \ac{MAT} assicura l'equivalenza dell'ipotesi col target.
A tal fine si riporta preliminarmente il seguente teorema (\cite{Angluin87}):
\begin{teorema}
\label{teo:angm}
Se una tabella di osservazione è completa,chiusa e consistente, allora l'ipotesi \ac{H} (quella inferita dall'algoritmo \ref{alg:lstar-buildautomaton}) è consistente con la funzione OT. Qualsiasi altra ipotesi consistente con OT ma non equivalente ad \ac{H} deve avere più stati.
\end{teorema}
Nel teorema \ref{teo:angm} con ipotesi consistente con la funzione OT si intende che $\forall u \in \text{STA e } \forall e \in \text{EXP},  ue \in \ac{L} \iff \text{OT}[u][e] = 1$

Il risultato del teorema \ref{teo:angm} è che qualunque DFA consistente con OT o è isomorfico all'ipotesi inferita da L* o contiene almeno uno o più stati. Quindi ogni ipotesi \ac{H} fatta da L* è sempre il minimo DFA consistente con OT.

Un altro risultato che ci torna utile è:
\begin{lemma}
\label{lem:fgv}
Detto n il numero di differenti valori di $row(s) \text{ per } \forall s \in \text{RED}$ in una tabella di osservazione. Qualsiasi \ac{H} consistente con OT deve avere almeno n stati
\end{lemma}
Si indica con n il numero di stati del DFA minimo accettante \ac{L}. E' facile dimostrare che il numero di valori distinti di $row(s) \text{ per } s \in \text{ RED} $ è incrementato monotonicamente fino ad un massimo di n durante l'esecuzione di L*. Infatti sia la chiusura che la consistenza introducono un nuovo stato RED. Se la tabella fosse già chiusa e consistente il controesempio $t$ tornato dal \textit{teacher} comunque garantisce che un nuovo stato RED venga aggiunto alla tabella di osservazione: detto $T_u$ il DFA \textit{target} minimo (ovviamente consistente con OT) --- il controesempio $t$ ci permette di dedurre che \ac{H} e  $T_u$  non sono equivalenti ---  , allora dal teorema \ref{teo:angm} sappiamo che \ac{H} ha al massimo $n-1$ stati. Inoltre L* classificherà il controesempio $t$ allo stesso modo di $T_u$ e quindi il nuovo DFA ipotesi \textit{H'} che  si otterrà  non sarà equivalente ad \ac{H} (per via di t) e inoltre sarà consistente con OT, quindi dal teorema \ref{teo:angm}  si deduce che \textit{H'} deve avere almeno n stati (almeno 1 stato in più di \ac{H}).

Questo dimostra che ad ogni passo del ciclo più esterno di L* almeno uno stato RED distinto deve essere aggiunto sempre alla tabella di osservazione. Quando ci saranno n stati RED distinti L* troverà il DFA \textit{target} minimo consistente con OT infatti il DFA \textit{target} minimo è sempre consistente con OT\footnote{Ma se sia il \textit{target} che \ac{H} sono sempre consistenti con OT come si fa a trovare un controesempio? La risposta è semplice: da OT viene creata un' ipotesi \ac{H} consistente all'OT ma nell'ipotesi possono essere \textit{parsate} anche altre stringhe non contemplate in OT da cui può derivare la non equivalenza con il \textit{target}} e l'ipotesi creata da L* è sempre il DFA minimo per il teorema \ref{teo:angm} e dal lemma \ref{lem:fgv} si ha che l'ipotesi creata da L* deve avere almeno n stati.
Essendo il DFA ipotesi un DFA ipotesi minimo e con n stati e consistente con T non può essere che uguale o isomorfo col DFA \textit{target minimo}.  Quindi L* dovrà costruire nel caso peggiore $n-1$ ipotesi errate prima di trovare l'ipotesi corretta e quindi il numero di \ac{EQ} è al massimo n (perchè l'ipotesi corretta comunque va sottoposta al \textit{teacher})

\subsubsection{Complessità computazionale}\label{subsub:comcom}Come detto in precedenza la complessità computazionale di L* è limitata da un polinomio dipendente dal numero di stati del DFA minimo identificante \ac{L} e dalla lunghezza del controesempio più lungo ritornato dal \textit{teacher}.In \cite{Angluin87} si trova una dimostrazione dettagliata di quanto detto sopra. In questa sede si analizzano dei parametri oggettivi nella valutazione del costo computazionale cioè il numero di \ac{MQ} e di \ac{EQ}. In quest'analisi si terrà conto anche di k un ulteriore parametro che rappresenta la dimensione dell'alfabeto. Il numero di \ac{EQ} sarà limitato da n (sottosezione correttezza \ref{sub:cor}) come dimostrato in precedenza. Il numero di \ac{MQ} è invece limitato dalla dimensione della tabella di osservazione. Il numero di elementi in EXP non può eccedere n , in quanto l'insieme EXP viene incrementato di un elemento quando la tabella di osservazione è inconsistente (algoritmo \ref{alg:lstar-consistent}) e l'inconsistenza può presentarsi al più $n-1$ volte cioè ogni volta che viene aggiunto un nuovo nodo RED distinto (con $n$ nodi RED distinti L* termina quindi se ne aggiungono al più $n-1$) (la dimensione di EXP è al più n e non $n-1$ perchè EXP inizialmente contiene $\lambda$).EXP rappresenta il numero di colonne della tabella di osservazione, adesso si calcola il numero di righe della stessa. Si indica con $m$ la lunghezza del controesempio più lungo ritornato dal \textit{teacher}. Il numero di stati RED non può eccedere $n+m(n-1)$  perchè gli stati RED sono aggiunti quando si scopre che la tabella non è chiusa e quando il \textit{teacher} torna un controesempio.  La non chiusura può accadere al più $n-1$ volte ed ogni volta aggiunge uno stato RED, e ci possono essere massimo $n-1$ controesempi ognuno dei quali può causare l'aggiunta di al più $m$ stati RED (i prefissi aggiunti ad ogni iterazione sono al più pari alla lunghezza del controesempio e nel caso peggiore in cui tutti i controesempi sono lunghi m il numero dei prefissi aggiunti ad ogni iterazione è $m$). Il numero degli stati BLUE è al più $k(n+m(n-1))$ perchè i BLUE, che rappresentano le transizioni, sono ottenuti concatenando tutti i simboli dell'alfabeto agli stati RED. Quindi la dimensione della tabella sarà $\text{righe} * \text{colonne}$ cioè $\text{(RED}+\text{BLUE)}*\text{EXP}$ quindi si ha:
\begin{equation*}
(k+1)(n+m(n-1))\,n = \mathcal{O}(kmn^{2})
\end{equation*}
che è il numero di \ac{MQ} totali.
\subsection{Il teacher} 
\label{sub:tea}Il teacher di L* essendo un \ac{MAT} è chiamato a rispondere a due tipi di query: \ac{MQ} ed \ac{EQ}. Si suppone che esso abbia a disposizione il DFA che identifica \ac{L} quindi è immediato rispondere a una \ac{MQ}. Il \textit{teacher} deve anche vagliare l'equivalenza del target con l'ipotesi fornitagli dal \textit{learner} e in caso di inequivalenza deve tornare un controesempio. A tal fine il \textit{table-filling algorithm} \cite{Nor09} risulta essere un buon algoritmo (il più performante con complessità quasi lineare atto solo a testare l'equivalenza e tornare una witness  quindi senza consentire anche la minimizzazione è \cite{Hop71} )
\subsubsection{Table-filling}Il \textit{table-filliling} \cite{Nor09} è un algoritmo in grado di individuare ricorsivamente tutti gli stati tra loro distinti, alla fine dell'esecuzione le coppie di stati non marcati come tali saranno coppie di stati equivalenti. Per questo motivo l'algoritmo di table-filling è utilizzato anche nella minimizzazione di DFA dove gli stati trovati equivalenti saranno fusi in un unico stato.

Per stati distinti si intende stati per cui esiste almeno una stringa che partendo da quei due stati (e non dallo stato iniziale) giunge in una coppia di stati di arrivo composta da uno stato accettante e da uno stato rigettante.

Inizialmente si distinguono le coppie di stati che non sono equivalenti cioè gli stati che vengono distinti dalla stringa vuota cioè quelle coppie di stati formate da uno stato accettante e da uno rigettante. Al passo successivo si procede esaminando tutte le coppie di stati che momentaneamente l'algoritmo considera equivalenti (che non ha marcato come distinti nei passi precedenti): se per un simbolo dell'alfabeto $s$ da quella coppia di stati di partenza si arriva a una coppia di stati distinti (già marcati dall'algoritmo nei passi precedenti) anche la coppia di stati di partenza va marcata come distinti perchè se gli stati di arrivo sono distinti vuol dire che esiste un suffisso $w$ che li distingue quindi gli stati di partenza saranno distinti dalla stringa $sw$. Questa procedura va ripetuta ed ha termine quando al passo corrente l'algoritmo non ha trovato nessuna nuova coppia di stati distinti.Inoltre come attesta il seguente teorema:
\begin{teorema*}
Se due stati non sono marcati come distinti dall'algoritmo di table-filling, allora questi stati sono equivalenti. \cite{Hop07}
\end{teorema*}
si ha che  quando vengono identificati gli stati equivalenti è possibile passare alla minimizzazione tramite il merge di questi stati.

Per testare l'equivalenza di due DFA si manda in esecuzione il \textit{table-filling} sul DFA costituito dall'unione dei due DFA di cui verificare l'equivalenza. Se al termine dell'esecuzione i due stati iniziali risultano equivalenti i due DFA di partenza saranno equivalenti perchè non esiste nessuna stringa che distingue i due stati iniziali e quindi i due linguaggi dei due DFA sono identici. Per ottimizzare l'esecuzione è possibile interrompere l'esecuzione non appena viene individuato che i due stati iniziali sono distinti.

Per abilitare il \textit{teacher} a ritornare, in caso di inequivalenza, una \textit{witness} è necessario modificare leggermente il \textit{table-filling}. Anzichè limitarsi nel marcare le coppie di stati non equivalenti è necessario anche memorizzare il simbolo dell'alfabeto che ha causato l'inequivalenza. Inoltre bisogna marcare con la stringa vuota o con un marcatore speciale le coppie di stati distinti in fase d'inizializzazione . Quando l'algoritmo termina è possibile creare il controesempio, partendo dalla coppia di stati iniziali, percorrendo la struttura dati usata durante il \textit{table-filling} con l'ausilio delle funzioni di transizione dei due DFA e del marcatore memorizzato fino a quando non viene trovata una coppia di stati contrassegnata con la stringa vuota (cioè uno stato accettante e l'altro no). E' garantito che un controesempio venga sempre individuato ma non vi è la garanzia che ad essere scovato sia quello di lunghezza minima.
\subsubsection{Una versione più efficiente}
Il \textit{table-filling} ha una complessità polinomiale rispetto ad n cioè alla somma del numero degli stati dei DFA di cui si vuole testare l'equivalenza. Si avranno $n*\frac{n-1}{2}$  coppie distinte di stati che verranno tutte considerate ad ogni visita della tabella (la struttura dati mantenuta dall'algoritmo) quindi $\mathcal{O}(n^{2})$. Nel caso peggiore ad ogni iterazione una sola coppia verrà scoperta essere distinta e le coppie sono tutte distinte il numero di iterazioni sono al più  $\mathcal{O}(n^{2})$ . Moltiplicando le due complessità si ottiene $\mathcal{O}(n^{4})$ che è il costo computazionale nel caso peggiore.

E' possibile migliorare la complessità computazionale a $\mathcal{O}(n^{2})$ memorizzando per ogni coppia di stati $(i,j)$ una lista di dipendenza costituita da tutte quelle coppie (x,y) che tramite un singolo simbolo dell'alfabeto $k$ arrivano in $(i,j)$ cioè $\hat{\delta}(x,k)=i$ e $\hat{\delta}(y,k)=j$ .
Si memorizzano in una coda tutte le coppie di stati inizialmente distinte. Si estrae una coppia dalla coda (che quindi è distinta) e tutte le coppie che da essa dipendono sono marcate come distinte nella tabella e sono aggiunte in fondo alla coda. L'algoritmo ripete questi passi finchè la coda è vuota.