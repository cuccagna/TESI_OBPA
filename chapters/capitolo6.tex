%!TEX encoding = UTF-8 Unicode
%!TEX root = ./../main.tex
%!TEX TS-program = xelatex

\chapter[OBP App.]{Observation Pack Approssimato} % chapter 6 title
\label{cap:sei}
L'obiettivo di questo lavoro è indagare la capacità di apprendere linguaggi regolari in uno scenario di \textit{Active Learning}, nel caso in cui non si disponga di un \textit{Oracolo} capace di rispondere nativamente nè ad \ac{EQ} nè a \ac{MQ}.  
In letteratura esistono diversi algoritmi utilizzati per  l'appredimento di linguaggi regolari. 
L' approssimazione dell' \textit{Oracolo} è  indipendente dallo specifico algoritmo d'\ac{IIR}, tuttavia per renderlo concreto l'attenzione è stata focalizzata sull'\ac{ObP}.
Allo stato dell'arte l' \ac{ObP} costituisce il secondo algoritmo di riferimento nell'ambito dell'apprendimento di linguaggi regolari.  L'algoritmo più performante è invece il più recente TTT algorithm \cite{SteffenTTT14}. Si è scelto di utilizzare \ac{SVM} come classificatore atto a modellare un \textit{Oracolo}, classificatore costruito a partire da alcuni esempi positivi e negativi del linguaggio da apprendere. Sarebbe opportuno preventivamente leggere le Appendici \ref{cap:cinque}  e \ref{app:tre} dato che i concetti e le tecniche lì descritte sono propedeudiche all'algoritmo qui delineato.\\
 Data la natura non esatta dell'algoritmo ivi realizzato questo viene indicato come \ac{ObPA}.\\
  Corredata a questa tesi vi è anche l'implementazione dell' \ac{ObP} in C++11 , codice che è stato integrato in  Gi-learning \cite{Cot16} una libreria preesistente. Nelle applicazioni reali tuttavia è altamente improbabile la disponibilità di un \textit{Oracolo} in grado di rispondere a delle \ac{EQ} da cui l'esigenza di un \textit{Oracolo approssimato} e dell'\ac{ObPA} la cui relativa implementazione oggetto di tesi è stata parimenti integrata in  Gi-learning \cite{Cot16}.

\section{Precedenti lavori in letteratura}
Assumere che il \textit{teacher} sia in possesso del formalismo del linguaggio target \ac{L} è uno scenario poco plausibile essendo esso stesso l'oggetto dell'inferenza.
Quindi l'obiettivo delineato in questa tesi è indagare il comportamento di un algoritmo di \textit{active learning} per inferire il \ac{DFA} A tale che $L(A) =\ac{L}$ tramite un oracolo approssimato realizzato con un classificatore statistico e tale intento si discosta dai lavori preesistenti in letteratura. In realtà una prima versione di un algoritmo di \textit{active learning} che realizza un Oracolo approssimato è già presente in Angluin \cite{Angluin87} in cui si approssima un \ac{EQ} tramite un certo numero di \ac{MQ} nella sua versione di L* approssimato. Più di recente, nella stessa direzione è andata la competizione Zulu \cite{Zulu10}: il vincitore della competizione \cite{Howar12} definisce il nuovo tipo di query: l'  \textit{Identity Query}
\begin{definizione*}[Identity Query] Testa se due prefissi $u,u'$ sono nella stessa classe di equivalenza del target A cioè se $u \not\simeq_{\lambda^{A}} \! u'$. In caso $u \not\simeq_{\lambda^{A}} \! u'$ ritorna un suffisso $v$ per il quale $\lambda^{A}(uv) \neq \lambda^{A}(u'v)$. Altrimenti ritorna il successo. 
\end{definizione*}
e dimostra che i linguaggi regolari possono essere inferiti con un numero polinomiale di \ac{MQ} ed \textit{Identity Query}.       
Le \textit{Identity Query} non sono meno realistiche delle \ac{EQ} ma forniscono un framework per organizzare le \ac{EQ} incrementalmente in modo da approssimarle in maniera relativamente facile ed efficiente tramite \ac{MQ}.  Anche gli altri algoritmi in letteratura sono focalizzati sulla ricerca di algoritmi che in maniera efficiente riescono ad approssimare le \ac{EQ} tramite \ac{MQ}.  In questa sede si assume invece l'impossibilità di rispondere nativamente anche alle \ac{MQ} oltre che alle \ac{EQ}, cioè  anche l'esito delle \ac{MQ} non è noto ed andrà approssimato.

Per quanto concerne la selezione del classificatore statistico per approssimare l'Oracolo la scelta è ricaduta su \ac{SVM} perchè costituiscono uno dei migliori modelli. Inoltre sono poche le applicazioni delle \ac{SVM} per l'apprendimento di linguaggi regolari come in \cite{Clark11}\cite{Clark06}  in cui si riesce a definire un kernel string utile per l'apprendimento dei linguaggi planari\footnote{I linguaggi planari sono una classe di linguaggi che attraversano la tassonomia di Chomsky nel senso che apprendono solo in maniera parziale i linguaggi finiti,regolari,context-free,context-sensitive ecc. senza saturare nessuno di essi}  oppure in \cite{Kontorovich09} dove si delinea un lavoro teorico sui linguaggi regolari e si propone un kernel string senza concretizzarlo specificamente per l'apprendimento di linguaggi regolari nell'accezione dell'\textit{active learning}. Altri tipi di classificatori come ad esempio le \textit{Recurrent Neural Network} si sono rilevate particolarmente adatte allo scopo di modellare un \ac{DFA} ma come si evince da \cite{Forcada02}, che costituisce una panoramica su di esse a riguardo dell'impiego in  \ac{GI}, sono state già ampiamente dibattute in letteratura.

\section{Funzionamento ObPA}
Una preliminare osservazione per evitare la creazione di ambiguità nel prosieguo consiste nel rimarcare che il codice prodotto è costituito da una duplice versione. Vi è infatti il codice riguardante la fase di \textit{debug} riferito d'ora in avanti come \textit{debug version} e quello pronto per l'utilizzo reale riferito d'ora in avanti come \textit{release version}\footnote{In realtà esiste un unica versione del codice ma si passa da una versione all'altra attivando o disattivando il flag in compilazione DEBUG$\_$EVALUATION (se è definito si sta optando per la \textit{debug version})}.  Con l'intento di spiegare le differenze principali tra le due versioni e contemporaneamente introdurre l'\ac{ObPA} vengono forniti gli pseudocodici \ref{alg:obpad} e \ref{alg:obpar} di alto livello:

\begin{algorithm}
\caption{OBPA \textit{debug version}}\label{alg:obpad}
\begin{algorithmic}[1]
\Statex
\Input il \ac{DFA} target $A$,l' alfabeto $\Sigma$ 
\Output il \ac{DFA} inferito $Ob\_DFA$
\State $samples \gets A.random\_walk(750,750)$
\State $training\_set \gets pull\_out(samples,500)$
\State $test\_set \gets pull\_out(samples,1000)$
\State $appr\_oracle \gets \textbf{new}\:\: appr\_oracle(|\Sigma|,\Sigma,training\_set,test\_set)$
 \LineComment{Sul training\_set si addestra SVM e con il  \textit{test\_set} si fa model evaluation}
\State $Ob\_DFA \gets OBSERVATION\_PACK(appr\_oracle).run()$
\State $statistical\_measure \gets compare(Ob\_DFA , A)$
 \State \textbf{return} $Ob\_DFA$
     
\end{algorithmic}
\end{algorithm}




\begin{algorithm}
\caption{OBPA \textit{release version}}\label{alg:obpar}
\begin{algorithmic}[1]
\Statex
\Input l' alfabeto $\Sigma$
\Output il \ac{DFA} inferito $Ob\_DFA$
\State $training\_set \gets read\_file(path\_file)$ \Comment{Nel file samples disponibili all'utente}
\State $appr\_oracle \gets \textbf{new}\:\: appr\_oracle(|\Sigma|,\Sigma,training\_set)$
 \LineComment{Sul training\_set si addestra SVM e non si effettua  model evaluation}
\State $Ob\_DFA \gets OBSERVATION\_PACK(appr\_oracle).run()$
 \State \textbf{return} $Ob\_DFA$
     
\end{algorithmic}
\end{algorithm}

La differenza principale tra le due versioni è che nella \textit{debug version} si è in possesso del \ac{DFA} target e nella \textit{release version} non si possiede in alcun modo questa conoscenza.  Si generano 1500 campioni bilanciati campioni con un particolare algoritmo ,\textbf{random walk}.  Dai campioni iniziali si estraggono il \textit{training set} di 500 elementi e il \textit{test set} composto dai rimanenti 1000. Si crea un oracolo approssimato che provvede internamente a costruire un classificatore a partire dal \textit{training set} e usa il \textit{test set} per valutare il classificatore scelto. Si invoca l'\ac{ObP} passandogli l'Oracolo approssimato; \ac{ObP} funziona in maniera classica come descritto nel capitolo \ref{cap:quattro} ma al momento di invocare i metodi per effettuare le \ac{MQ} ed \ac{EQ} saranno chiamati i metodi dell'Oracolo approssimato --- che \ac{ObP} ''ha'' (composizione)--- che saranno realizzati mediante il classificatore precedentemente costruito. Viene inferito un \ac{DFA} che viene confrontato con il \ac{DFA} target tramite delle misure statistiche.  L'algoritmo \textit{random walk} nonchè la scelta della dimensione del \textit{training set} e del \textit{test set}  e come avviene il confronto tra il target e il \ac{DFA} inferito sarà spiegato più approfonditamente nella sezione \ref{sec:gensam}.\\
Nella \textit{release version} non essendo in possesso di un \ac{DFA} target ,come accade del resto in uno scenario reale, i campioni in possesso dell'utente vengono inseriti su un file e una volta caricati nel programma costituiscono essi stessi il \textit{training set}. Come per la \textit{release version} si costruisce un Oracolo approssimato ma non si effettua model evaluation (non c'è un \textit{test set}) e il perchè sarà spiegato successivamente. Alla stregua di quanto descritto per la \textit{release version} si inferisce un \ac{DFA} mediante l'algoritmo \ac{ObP} ma non è possibile effettuare una comparazione di quest ultimo con il \ac{DFA} target dato che è ignoto. \\
Si puntualizza che la \textit{release version} è stata implementata generando i campioni comunque su un \ac{DFA} target anzichè inserirli e poi leggerli da file proprio per non doversi sobbarcare  l'onere di generare manualmente i campioni. 

\subsection{Costruzione del classificatore}
Come capita spesso nell'addestramento di un classificatore  sono molti gli \textit{iperparametri} da potere regolare e le possibili strade perseguibili per di cercare una soluzione soddisfacente. Per questo motivo sono state realizzate tre diversi implementazioni nominate in seguito come \ac{ObPA}1 \ac{ObPA}2 e \ac{ObPA}3. Per ognuna di esse vi è sia una \textit{debug version} che una \textit{release version}. Per ciascuna di esse l'implementazione fornita negli algoritmi \ref{alg:obpad} e \ref{alg:obpar} rimane valida ma cambiano le tecniche utilizzate per costruire il classificatore per l'oracolo approssimato a partire dal \textit{training set}.

\subsubsection{ObPA1}
Come detto il modello prescelto è \ac{SVM} e la libreria esterna scelta è l'implementazione di Thorsten Joachims nella versione $\ac{SVM}^{light}$ e per ulteriori dettagli si rimanda all'Appendice \ref{sec:light}. Qui si aggiunge che che $\ac{SVM}^{light}$ è in linguaggio C mentre la libreria GI-learning è in C++, che è concepita come un eseguibile pronto all'uso, che è una libreria povera  in termini delle tecniche di \textit{data processing} e model selection, che è stato necessario integrarla all'interno di GI-learning. Quindi è stato necessario un notevole sforzo implementativo per aggiungere alcune funzionalità di cui si parlerà a breve (k-fold-validation, codifica, scaling ecc.) e non è stato possibile utilizzare  $\ac{SVM}^{light}$ come una \textit{black-box} ma interagire con essa a basso livello e modificare porzioni di codice e la \textit{signature} di alcune funzioni interne per riadattarle agli scopi di \ac{ObPA}.

L'algoritmo \ac{ObPA}1 (la parte relativa all'addestramento del classificatore) viene presentata a grandi linee nell'algoritmo \ref{alg:obpa1} corrispondente a una particolarizzazione di quello che negli algoritmi \ref{alg:obpar} e \ref{alg:obpad} è stato indicato con $appr\_oracle$.

\begin{algorithm}
\caption{OBPA1}\label{alg:obpa1}
\begin{algorithmic}[1]
\Statex
\Input a $TRS = training\_set$, a $TES = test\_set$, a $\Sigma$   
\Output $app\_oracle$
\State $encode(TRS , TES)$
\State $padding(TRS , TES)$
\State $scale(TRS , TES)$
\State $\textbf{best\_model} \gets grid\_search(TRS)$ \Comment{Si fa model selection}\label{sta:quattro}
\State $new\_best\_model \gets$ retrain $\textbf{best\_model}$ found, on whole TRS
\State $statistical\_results \gets model\_evaluation(new\_best\_model,TES)$ \label{sta:moe}
\State $\textbf{return}$ app\_oracle(new\_best\_model) 

   
\end{algorithmic}
\end{algorithm}
Nell'algoritmo \ref{alg:obpa1} è stata presentata la \textit{debug version} di \ac{ObPA}1 , la \textit{release version} differisce solo per la riga \ref{sta:moe} e per l'assenza del \textit{test set} quindi per essa non si fa \textit{model evaluation} come si approfondirà a breve.\\
I dati devono essere necessariamente processati perchè essendo categorici (l'alfabeto in generale è fatto da stringhe di caratteri alfanumerici) sono direttamente utilizzabili da \ac{SVM} e allora li si rende numerici con \textbf{integer encoding} (Appendice \ref{subsub:ien} ).\\
\ac{SVM} presuppone che i campioni siano della stessa lunghezza ed ecco giustificato il \textit{padding}. Si seleziona la stringa più lunga nel \textit{training set} e tutte le altre stringhe sono uniformate a questa lunghezza tramite il \textit{padding}. Siccome \ac{SVM} si basa su misure di similarità tra i campioni (Appendice \label{subsub:prscal}) non è stato ritenuto opportuno scegliere un valore fisso per il valore di padding che è allora diventato un parametro.\\
Dato che i singoli attributi variano nello stesso range e come si dirà si è usato un \textit{kernel} gaussiano che non ha problemi numeri lo \textit{scaling} dei dati non è strettamente necessario ed allora se effettuarlo o meno e diventato un altro parametro. La tecnica usata per lo \textit{scaling} è quella della \textbf{standardizzazione} e per i dettagli si rimanda all'Appendice \ref{subsub:scal}. In seguito va fatta model selection per la scelta degli \textit{iperparametri migliori}. Si è scelto il \textit{kernel} gaussiano per i motivi ampiamente illustrati nell'Appendice \ref{sec:adsvm} e l'intervallo di variazione del parametro $\gamma$ del \textit{kernel} nonchè del parametro $C$(trade-off parameter) è quello indicato nella sezione \ref{sec:adsvm} in cui è anche spiegato che una ricerca come \textit{grid search} per la selezione dei parametri migliori malgrado sia molto onerosa computazionalmente sia la più affidabile.  Per il parametro $C$ è anche usato il valore du default della libreria \ac{SVM}. Il padding è settato con 8 valori positivi diversi più due valori negativi e nel caso che il valore di padding positivo corrente non produca un classificatore migliore rispetto a un valore di padding precedente si passa direttamente all'ultimo valore di padding saltando quelli intermedi. In definitiva vi sono quattro parametri lo scaling,il padding,$C$,$\gamma$ che rende molto grande lo spazio dei parametri.\\


Discorso a parte meritano la model selection e la model evaluation. Innanzitutto  si è scelto di utilizzare per avere stime il più possibile unbiased la \textit{5-fold-validation}. $\ac{SVM}^{light}$ mette a disposizione anche \textit{LOO} ma ne calcola solo un'approssimazione e quindi non del tutto attendibile nonostante ciò  \ac{ObPA} è implementato in modo tale da potere scegliere dall'esterno la preferenza sul metodo di validazione incrociata (LOO o 5-fold-validation).  Un altro criterio di stima dell'errore messo a disposizione da $\ac{SVM}^{light}$ è  Xi-Alpha che viene calcolato in maniera molto efficiente ma come si evince da \cite{Duan03} 5-fold-validation è più attendibile.  \\Il modo di procedere classico sarebbe quello di dividere i campioni disponibili (cio quelli menzionati come $TRS$ alla riga \ref{sta:quattro} in due parti un \textit{training set} e un \textit{test set} . Sul \textit{training set} si fa \textit{5-fold-validation} e si usa la media dei cinque valori di \textit{accuracy} per fare model selection. Per il modello migliore trovato (e i suoi parametri) si rieffettua l'addestramento usando tutto il \textit{training set} che è non quello indicato come $TRS$ ma quello originato dalla divisione sull'insieme iniziale $TRS$. Per il classificatore costruito si fa model valuation utilizzando gli \textit{unseen} campioni del \textit{test set}(quello originato dalla suddivisione dell'insieme $TRS$) (con qualche misura come MCC)  e infine si rieffettua l'addestramento su tutti i campioni  iniziali (cioè i 500 campioni di $TRS$). \\
In \ac{ObPA}1 (e anche nelle altre versioni) in \textit{release version} si è fatta una scelta diversa. Con l'intento di ottimizzare le prestazioni e di usare il massimo numero di campioni per la scelta del modello si fa solo model selection tramite \textit{5-fold-validation} su tutti i campioni (i 500 campioni di $TRS$) riaddestrando dopo la scelta dei migliori \textit{iperparametri} su tutto l'insieme di campioni $TRS$ e rinunciando a fare model evaluation. Quindi non verrà fornito un \textit{feedback}  sulle capacità di generalizzare del costruito classificatore statistico all'utente dato che quest ultimo potrà visionare solo l'accuracy della \textit{5-fold-validation} che è indicativa ma non una stima precisa dell'errore di generalizzazione.\\
In \textit{debug version} si effettua la stessa cosa che in \textit{release version} ma avendo il \ac{DFA} target i campioni sono disponibili e ne vengono generati 1000 dall'esterno (senza sovrapposizione con quelli del \textit{training set}) che serviranno da \textit{test set} per fare model evaluation sul migliore modello scelto (si ribadisce scelto alla stregua della \textit{release version}).\\
Due aspetti importanti relativi a quanto appena esposto sono:
\begin{enumerate}
\item I campioni del \textit{test set} vanno processati con gli stessi valori trovati nella fase di preprocessing per il training set. Tali valori non vanno quindi ricalcolati \textit{ex novo} sul \textit{test set}.
\item Dal \textit{test set} vanno scartate le eventuali stringhe di lunghezza maggiore della stringa di lunghezza massima tra quelle incontrate nel \textit{training set}. Quindi il classificatore costruito ha il limite di funzionare solo su stringhe fino ad una certa lunghezza. Quindi se \ac{ObP} dovesse formula una \ac{MQ} più lunga di quella di lunghezza massima incontrata nel \textit{training set} il classificatore non è in grado di rispondere. 
\end {enumerate}

\subsubsection{ObPA2}
In \ac{ObPA}2 si usa come codifica dei dati \textbf{OHE} (vedasi Appendice \ref{subsub:ohe}) la cui rappresentazione risultante è quella in cui ogni stringa rappresenta un vertice dell'ipercubo di lato unitario. Questa è una rappresentazione molto sparsa e ridondante, per cui incline all'\textit{overfitting}, ma nella fattispecie i molti gradi di libertà potrebbero tornare utile per la rappresentazione ostica dei linguaggi regolari.\\
Rispetto a quanto esposto su OHE nell'Appendice {subsub:ohe} occorre un bit in più per tenere in considerazione il valore per il padding. Ad esempio se l'alfabeto $|\Sigma|=3$ in OHE si ha:
\begin{equation*}
1000 \quad 0100 \quad 0010 \quad 0001
\end{equation*} 

laddove l'ultimo elemento è la codifica OHE per il valore di padding mentre i primi tre elementi servono a codificare le stringhe che costituiscono l'alfabeto $\Sigma$.\\
Tutte le considerazioni effettuate per \ac{ObPA}1 restano valide per \ac{ObPA}2. Le uniche differenze a parte quella suddetta sono che il valore di padding è unico e che per la codifica OHE non è necessario effettuare lo scaling quindi vengono a decadere due parametri velocizzando l'algoritmo. Il rovescio della medaglia è che il numero di attributi per stringa aumenta notevolmente e per stringhe o alfabeti molto lunghi questo metodo può allungare notevolmente l'onere computazionale per la convergenza dell'algoritmo  della librearia $\ac{SVM}^{light}$  

\subsection{Aprrossimazione di EQ e MQ}
Terminata la fase di addestramento e costruzione del classificatore la successiva fase  è  del tutto analoga a quanto visto per i metodi classici di \textit{active learning} e nella fattispecie \ac{ObP}. La sostanziale differenza in \ac{ObPA} è che le \ac{MQ} ed \ac{EQ} sono realizzate mediante l'oracolo approssimato e in ultimo mediante il classificatore precedentemente realizzato.
\subsubsection{MQ approssimata}
L'approssimazione di una \ac{MQ} per una stringa $s$ è quasi immediata. Se $|s|$ supera la lunghezza della stringa più lunga incontrata in fase di addestramento si lancia un'eccezione ma in pratica l'algoritmo termina perchè è una situazione ingestibile. Quanto detto è vero solo per \ac{ObPA}1 e \ac{ObPA}2 mentre \ac{ObPA}3 riesce a gestire stringhe di lunghezza diversa. Si effettua il preprocessig di $|s|$ a secondo della versione di \ac{ObPA} utilizzata e si etichetta la stringa come positiva e si effettua la predizione.\footnote{la predizione avviene scrivendo la stringa post-elaborata su file nel formato adeguato per $\ac{SVM}^{light}$ e si invoca la funzione che effettua la predizione passandogli il percorso del file dove c'è la stringa post-elaborata e il file dove è memorizzato il migliore modello precedentemente trovato.} Se si ottiene una previsione corretta (accuracy tornata del 100$\%$) la stringa è positiva secondo il classificatore altrimenti (accuracy nulla) la stringa è negativa. Per questioni di efficienza per evitare la scrittura su file in \ac{ObPA}3 interagendo a basso livello con la libreria \ac{SVM} si è riusciti a prendere il vettore dei pesi w in modo da realizzare la \ac{MQ} come $sign(w \bullet s + b)$ (spiegazione nell'Appendice  \ref{sub:fte}).
 
 \subsubsection{EQ approssimata}
L'idea è realizzare un \ac{EQ} (tra il \ac{DFA} \ac{H} e il classificatore che rappresenta il target) tramite una serie di \ac{MQ} su un insieme di stringhe. Il modo in cui è creato l'insieme di stringhe è spiegato dettagliatamente in \label{sub:ceq} cui si rimanda. L'\ac{EQ} è superata quando la percentuale di campioni dell'insieme  classificata alla stessa maniera sia dall'ipotesi \ac{H} che dal classificatore precedentemenete addestrato supera una certa soglia. La soglia è impostata come un parametro esterno. 
Avendo realizzato in \ac{ObPA}3 l'ottimizzazione che bypassa la lettura da file per effettuare una \ac{MQ} approssimata l'\ac{EQ} è effettuata come una successione di \ac{MQ} approssimate.



 


\section{Scelte Progettuali}
Un lavoro d'implementazione degno di nota è costituito dalla preliminare ingegnerizzazione del codice. Come detto il prescelto algoritmo di \textit{active learning} è stato \ac{ObP}, che nella sua versione base presentata nel capitolo \ref{cap:quattro} necessita di un \ac{DFA} target che funge da Oracolo onnisciente. Nell'ottica di preservare questa versione dell'\ac{ObP} e contemporaneamente integrare nella libreria le funzionalità dell'\ac{ObPA} si è deciso di implementare una versione polimorfica. Più in dettaglio si è creata una gerarchia di classi per l'entità astratta Oracolo come in figura \ref{fig:eor}.
\begin{figure}[htp]
	\centering
	\includegraphics[ width=0.7\textwidth]{EreditaOracolo}
	\caption[Ereditarietà Oracolo]{Ereditarietà Oracolo}
   \label{fig:eor}
\end{figure}

L'algoritmo \ac{ObP} invece di possedere (composizione) un \ac{DFA} target ha un oggetto della classe base astratta Oracolo. Quando invoco il costruttore dell' \ac{ObP}  si deve passare anche l'indirizzo di un oggetto della classe Oracolo. Tramite il tipo di oggetto Oracolo(si ha un handle della classe base Oracolo che punta allo specifico oggetto della classe derivata passato) passato  viene determinato in maniera trasparente con il polimorfismo se si desidera utilizzare l'\ac{ObP} piuttosto che l'\ac{ObPA}. Le chiamate alle funzioni effettuate sull'oggetto Oracolo all'interno di \ac{ObP} hanno la stessa \textit{signature} , cioè le \ac{MQ} e le \ac{EQ} , ma il tipo dell'oggetto Oracolo passato determina automaticamente di quale classe derivata invocare le funzioni (che avranno diverse implementazioni a secondo se appartengono alla classe exactOracle o a quella approximateOracle).  In questo modo la classe dell'algoritmo \ac{ObP} ha subito pochissime modifiche  e il lavoro d'implementazione di questa tesi si è focalizzato sulla classe approximateOracle. Infine all'interno della classe observation\_pack , per impedire al \textit{client} di vedere le strutture dati e le modifiche effettuate su di esse  e in ultimo il modo in cui funziona l'algoritmo, è necessario effettuare una copia interna dell'Oracolo passato dal \textit{client} ma non conoscendo a priori di quale tipo, e quindi di quale classe, è l'Oracolo vi è stata la difficoltà su come invocare il costruttore di copia. A tal fine si è usata la tecnica del \textit{clone idiom} .Quando si ha un riferimento polimorfico cioè un 
  puntatore alla classe base che punta a un oggetto della classe derivata all'occorrenza può sorgere il problema di determinare qual è il tipo della classe derivata . Allora nella classe base si dichiara un metodo virtuale puro che tutte le classi derivate devono quindi implementare. Quest'implementazione consiste nella creazione dinamica  di un nuovo oggetto della classe derivata chiamando il costruttore di copia della classe derivata sull'oggetto corrente (tramite new classeDerivata(*this)). Questo nuovo oggetto creato verrà tornato al chiamante. Si noti che il costruttore di copia della classe derivata deve provvedere a chiamare il costruttore di copia della classe base e che in questi costruttori deve avvenire una deep copy di tutti i membri dinamici.   In figura \ref{fig:cba} l'interfaccia della classe base astratta.
  
 \begin{figure}[htp]
	\centering
	\includegraphics[ width=0.3\textwidth]{Oracolo}
	\caption[Interfaccia classe base Oracolo]{Interfaccia classe base Oracolo}
   \label{fig:cba}
\end{figure}    