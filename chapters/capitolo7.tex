%!TEX encoding = UTF-8 Unicode
%!TEX root = ./../main.tex
%!TEX TS-program = xelatex
\chapter{Risultati sperimentali} % 5th chapter title
\label{cap:sette}
La valutazione delle \textit{performances} di un algoritmo di \ac{GI} possono essere influenzate sia positivamente che negativamente da alcuni fattori come  evidenziato in \cite{Stamina10}. Alcuni di questi fattori riguardano la complessità del \ac{DFA} target:
\begin{itemize}
\item numero di stati
\item dimensione dell'alfabeto
\item la lunghezza del più lungo dei cammini minimi dallo stato iniziale a qualunque altro stato
\item il numero di transizioni totali\footnote{ (escluse quelle che vanno nello stato pozzo per i \ac{DFA})}
\end{itemize}

altri il ''sample set'':
\begin{itemize}
\item numero di campioni del \textit{training set} e del \textit{test set}
\item campioni suddetti strutturalmente completi
\end{itemize} 
Nell'effettuazione degli esperimenti è necessario tenerne conto onde evitare dei risultati pessimisticamente o ottimisticamente \textit{biased}. Per molti di questi parametri ci si è attenuti all'impostazione della competizione STAMINA \cite{Stamina10}.

\section{Dataset}
In letteratura si trovano molti algoritmi innovativi di \ac{GI} i quali ,non conoscendone ancora le caratteristiche, in fase di sperimentazione  sono stati preventivamente testati su dei linguaggi regolari ''non banali'' ma relativamente semplici. In un secondo momento i limiti dell'algoritmo sono testati contro linguaggi più complessi che ricalcano da vicino la complessità degli automi testati nelle varie competizioni di \ac{GI} o su dataset reali. Per le finalità di questo lavoro si è scelto di perseguire questa strada.

\subsection{Tomita Dataset}
Tomita in \cite{Tomita82} definisce sette linguagi regolari, da lui usati per provare il suo algoritmo di inferenza grammaticale basato sulla tecnica di hill–climbing. Succesivamente in \cite{Dupont94}, questo insieme viene ampliato aggiungendo altri otto linguaggi regolari. L'elenco completo dei quindici linguaggi regolari si trova in tabella \ref{tab:tom} e raggiunge un massimo di sei stati con $L_{10}$ e l'alfabeto è binario tranne in due casi, $L_{9}$ e $L_{15}$ , in cui $|\Sigma|$ = 3 . Alcuni di essi sono descritti dall’espressione regolare corrispondente. Nei casi in cui l’espressione regolare fosse troppo complicata al fine di capire immediatamente la “regolarità” del linguaggio, si è preferito fornirne una descrizione informale. Ad esempio l’espressione regolare per il linguaggio $L_6$ è $((a(ab)^{*}  (b|aa))|(b(ba)^{*} (a|bb)))^{*}$ : non è immediato riconoscere in questo caso la regolarità aritmetica posseduta dal linguaggio, costituito da tutte le stringhe in cui il numero dei caratteri $a$ differisce dal numero dei caratteri $b$ per un numero divisibile per tre.
 
\begin{table}[htp]
\centering 
\begin{tabular}{|c|M{0.75\textwidth}|} 
\hline
$L_{1}$ & $a^{*}$  \\
 \hline
 $L_{2}$ & $(ba)^{*}$  \\
 \hline
 $L_{3}$ & Ogni stringa che non contiene un numero dispari di a consecutivi dopo un numero dispari di b consecutivi  \\
 \hline   
 $L_{4}$ & Ogni stringa che non contiene la sottostringa aaa  \\
 \hline
 $L_{5}$ & Ogni stringa che contiene un numero pari di a ed un numero pari di b  \\
 \hline   
  $L_{6}$ & Ogni stringa in cui il numero di a contenute differisce dal numero di b
contenute per un numero divisibile per tre.  \\
 \hline  
 $L_{7}$ & $a^*b^*a^*b^*$  \\
 \hline
 $L_{8}$ & $a^*b$  \\
 \hline
  $L_{9}$ & $(a^*+c^*)b^*$  \\
 \hline
 $L_{10}$ & $(aa)^*(bbb)^*$  \\
 \hline
 $L_{11}$ & Ogni stringa che contiene un numero pari di a ed un numero dispari di b \\
 \hline 
 $L_{12}$ & $a(aa)^*b$ \\
 \hline     
 $L_{13}$ & Ogni stringa che contiene un numero pari di a \\
 \hline       
 $L_{14}$ & $(aa)^*ba^*$ \\
 \hline 
 $L_{15}$ & $bc^*b+ac^*a$ \\
 \hline 
\end{tabular}

 \caption[Linguaggi Tomita]{Linguaggi Tomita}
\label{tab:tom}
\end{table} 

\begin{figure}[htp]
\centering
\subfloat[$L_1$][$L_1$]
{\includegraphics[width=.40\textwidth,height=4cm,keepaspectratio]{Tomita1}} \label{sub:tom1}\quad
\subfloat[$L_2$][$L_2$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita2}} \label{sub:tom2}\\

\subfloat[$L_3$][$L_3$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita3}} \label{sub:tom3}\quad
\subfloat[$L_4$][$L_4$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita4}} \label{sub:tom4}\\

\subfloat[$L_5$][$L_5$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita5}} \label{sub:tom5}\quad
\subfloat[$L_6$][$L_6$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita6}} \label{sub:tom6}\\

\subfloat[$L_7$][$L_7$]
{\includegraphics[width=.50\textwidth,height=4cm,keepaspectratio]{Tomita7}} \label{sub:tom7}\quad
\subfloat[$L_8$][$L_8$]
{\includegraphics[width=.40\textwidth,height=4cm,keepaspectratio]{Tomita8}} \label{sub:tom8}\\
\caption{Linguaggi di Tomita}
\label{fig:ltom1}
\end{figure} 

\begin{figure}[htp]\ContinuedFloat
\centering
\subfloat[$L_9$][$L_9$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita9}} \label{sub:tom9}\quad
\subfloat[$L_10$][$L_{10}$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita10}} \label{sub:tom10}\\

\subfloat[$L_11$][$L_{11}$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita11}} \label{sub:tom11}\quad
\subfloat[$L_12$][$L_{12}$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita12}} \label{sub:tom12}\\

\subfloat[$L_13$][$L_{13}$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita13}} \label{sub:tom13}\quad
\subfloat[$L_14$][$L_{14}$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita14}} \label{sub:tom14}\\

\subfloat[$L_15$][$L_{15}$]
{\includegraphics[width=.45\textwidth,height=4cm,keepaspectratio]{Tomita15}} \label{sub:tom15}

\caption{Linguaggi di Tomita}
\label{fig:ltom2}
\end{figure} 

\subsection{Dataset casuale}
Un dataset di \ac{DFA} target sicuramente più probante dalla complessità paragonabile a quella delle applicazioni reali è stato creato estraendolo in maniera casuale. La librearia GI-learning non metteva a disposizione un metodo per l'estrazione di \ac{DFA} casuali ed allo scopo si è utilizzata una libreria esterna ,la LearnLib\footnote{\href{http://www.learnlib.de/}{http://www.learnlib.de/}}. Mediante la stesura di codice ad hoc ci si è interfecciati con la LearnLib e con il metodo \textit{randomICDFA} sono stati creati i \ac{DFA} casuali, infine si è convertiti i \ac{DFA} ottenuti nel formato specifico per la lettura e il caricamento degli automi all'interno di GI-learning. 
In precedenza si è detto che le performances sugli algoritmi di  \ac{GI} sono influenzate da diversi fattori ta cui la dimensione e il numero di stati del \ac{DFA} target che quindi sono parametri che vanno impostati in maniera oculata.
Sono stati creati sedici \ac{DFA} casuali con dimensione dell'alfabeto crescente che varia in $\{2,5,10,36\}$ e numeri di stati in $\{5,10,20,50\}$. Come dimensione massima dell'alfabeto si è scelto trentasei perchè corrispondente alla dimensione dell'alfabeto italiano più le dieci cifre del sistema decimale. Il limite superiore del numero di stati del \ac{DFA} target è stato fissato a cinquanta ricalcando la dimensione del \ac{DFA} target scelto   nelle varie competizioni di \ac{GI} come ABBANDINGO e STAMINA.\\
Data la complessità degli automi non è stata possibile la rappresentazione visuale come avvenuto per il dataset Tomita.  In tabella vi è un'associazione simbolica tra un'etichetta e la complessità del \ac{DFA} estratto che tornerà utile per la descrizione degli esperimenti.

\begin{table}[htp]
\centering 
\begin{tabular}{lcr} 
\toprule
$Etichetta$ & Stati & Alfabeto  \\
 \midrule
 $R_{1}$ & 5 & 2 \\
 $R_{2}$ & 10 & 2  \\
 $R_{3}$ & 20 & 2  \\
 $R_{4}$ & 50 & 2\\
 $R_{5}$ & 5 & 5\\
  $R_{6}$ & 10 & 5  \\
 
 $R_{7}$ & 20 & 5  \\

 $R_{8}$ & 50 & 5 \\
 
  $R_{9}$ & 5 & 10  \\

 $R_{10}$ & 10 & 10  \\
 $R_{11}$ & 20 & 10\\
 
 $R_{12}$ & 50 & 10 \\
 
 $R_{13}$ & 5 & 36 \\
    
 $R_{14}$ & 10 & 36 \\
 
 $R_{15}$ & 20 & 36 \\

 $R_{16}$ & 50 & 36 \\
 \bottomrule
\end{tabular}

 \caption[Dataset casuale]{Dataset casuale}
\label{tab:tom}
\end{table} 

\section[Gen. campioni da DFA]{Generazione di campioni da un DFA}
\label{sec:gensam}

Se si decidesse di generare  i campioni come stringhe casuali fino a una certa lunghezza in cui ogni simbolo costituente una stringa è estratto in maniera uniforme tra tutti i simboli dell'alfabeto si  incorrerebbe nel problema che  si verrebbe ad avere un insieme non bilanciato a causa della predominanza di campioni negativi dato che tipicamente su $\Sigma^*$ sono in minoranza le stringhe accettate da un \ac{DFA}. 
Inoltre  per l'addestramento di un classificatore e anche per un algoritmo di \ac{GI} è molto importante avere un insieme caratteristico (definizione \ref{def:car}) o perlomeno un insieme di stringhe che raggiunge gran parte degli stati e delle transizioni di un \ac{DFA}.
In \cite{Stamina10} è descritto un algoritmo in grado di assicurare con altà probabilità la completezza strutturale dei campioni e di produrre campioni bilanciati. L'algoritmo effettua un \textbf{random walk} sul \ac{DFA} target e si rimanda al riferimento per i dettagli.
La proprietà dei campioni di essere strutturalmente completi(c'è solo una probabilità alta che lo siano ma non la certezza) potrebbe condurre a delle stime ottimisticamente biased dell'algoritmo \ac{ObPA} dato che in uno scenario reale invece i campioni a disposizione dell'utente sono di norma del tutto casuali (anche con random walk lo sono ma come detto in modo da esplorare tutti i percorsi del \ac{DFA})  . Nonostante ciò si è deciso  di utilizzare comunque \textit{random walk}  perchè  questa procedura è diventata uno standard de facto per generare i campioni nelle competizioni tra algoritmi riguardanti \ac{GI}.

\subsection{W-Method}
\label{sub:wme}
Per la generazione di un \textit{test set} per fare model evaluation  è improbabile che delle stringhe generate casualmente testino adeguatamente un classificatore. Inoltre per la generazione del \textit{test set} dacade la valenza del discorso che campioni strutturalmente completi potrebbero condurre a sovrastimare positivamente un classificatore, assunto che rimane valido per il \textit{training set}, anzi il possedimento di questa proprietà dei dati nel \textit{test set} è ricercata per testare in maniera affidabile un classificatore che difatti approssima \ac{L}. Quindi l'utilizzo di \textit{random walk} per la generazione del \textit{test set} è assolutamente appropriato. \\   \ac{ObPA} però necessita anche del confronto dell'ipotesi intermedia \ac{H} ottenuta ad ogni \textit{round} con il \ac{DFA} target ma quest ultimo non è noto ma è approssimato da un classificatore\footnote{il classificatore approssima l'Oracolo, ma in ultima istanza ad essere approsimato è il linguaggio alias \ac{DFA} target dato che un Oracolo nel caso ideale ha il \ac{DFA} target e tramite esso risponde alle query} preliminarmente costruito tramite \ac{SVM} a partire dai campioni disponibili.   Di conseguenza l'\ac{EQ} come spiegato in \ref{subsub:eqa} va implementata sottoponendo  una serie di stringhe sia al classificatore che al \ac{DFA} ipotesi \ac{H} ed è fondamentale che queste stringhe siano selezionate attentamente. Estrarre le stringhe con l'algoritmo \textit{random walk} sul \ac{DFA} target in questo caso genera delle stringhe particolarmente significative ma solo per il \ac{DFA} \ac{H} e possibilmente non rappresentative del \ac{DFA} target dato che è ignoto.\\
 E ancora sia  \textit{random sampling} che \textit{random walk} possono produrre un \textit{test set} che ha alcuni campioni in comune con il \textit{training set} con cui è stato addestrato il classificatore che approssima l'oracolo ottenendo una possibile corrispondenza mistificatoria dell' \ac{EQ}.\\
 Inoltre  per la \textit{ideal version}, è possibile confrontare il \ac{DFA} finale inferito da \ac{ObPA} con il \ac{DFA} target ed anche in questo caso si ripresentano i problemi precedentemente esposti cioè eseguendo \textit{random walk} su uno dei due automi (o il target o l'ipotesi) potrebbe essere prodotto un insieme di stringhe per testare la similarità dei due linguaggi che non esplora parte dell'altro \ac{DFA} (quello su cui non si è eseguito \textit{random walk}) risultando quindi non del tutto appropriato allo scopo. Pertanto adesso è descritto l' algoritmo \textbf{W-Method} \cite{Chow78} che è esente dai problemi summenzionati.

\subsubsection{Algoritmo W-Method}

Tramite il W-Method nel contesto della \ac{GI} si realizza un' \ac{EQ} esatta impiegando solo \ac{MQ} \cite{Balanescu03}. Infatti esso crea, senza la necessità di avere il \ac{DFA} target A,  un \textit{test set}  $X$ dall'ipotesi \ac{H} in modo che se $\forall x \in X \:\:\: \lambda^{A}(x) = \lambda^{H}(x) \:\:\: \text{allora} \:\:\: A \cong \ac{H}$  (per rispondere alle \ac{MQ} lato target non è strettamente necessario avere il \ac{DFA} target ma si suppone uno scenario in cui si possa conoscere l'esito di $\lambda^{A}(x)$ senza la sua conoscenza ). Quindi il W-Method si può usare per realizzare un'\ac{EQ} in maniera esatta tramite \ac{MQ} tuttavia il numero di stringhe generate dal \textit{W-Method} può essere enorme e quindi subentrano problemi di efficienza. In questa tesi è incognito anche l'esito delle \ac{MQ} che è approssimato tramite le \ac{SVM} quindi l'\ac{EQ} realizzata tramite le stringhe prodotte dal \textit{W-Method} sarà comunque un'approsimazione. Inoltre quanto detto è vero se sono verificate alcune condizioni tra cui il numero esatto di stati del \ac{DFA} target   che in \ac{ObPA} non è noto nella \textit{release version} e può essere solo stimato producendo quindi un insieme di stringhe che approssimano l'equivalenza senza garantirla. Gli altri requisiti del \textit{W-Method} sono \cite{Balanescu03}:
\begin{itemize}
\item \ac{H} ed A sono deterministici
\item \ac{H} è canonico
\item Non ci sono stati irraggiungibili nè in \ac{H} nè in A
\item Si conosce $\norma{A}$
\item \ac{H} e A devono essere completamente specificati cioè da ogni stato per ogni $\Sigma$ si raggiunge uno stato che non sia lo stato pozzo(questa condizione può essere rilassata \cite{Balanescu03})
\end{itemize}
Si descrive brevemente il W-Method per sommi capi.   La ratio è che nel target si potrebbero avere degli extra-stati che non vengono esplorati con il \textit{test set} generato con metodi classici e che potrebbero causare un comportamento indesiderato ed alterare la valutazione senza averne avvisaglie. Si inizia stimando il numero di stati nel \ac{DFA} target (in modo che il test set esplori tutti gli stati del target). \'E importante eseguire il \textit{W-Method} sul \ac{DFA}  che ha il numero minore di stati (quando si usa il W-method nella \textit{ideal version} per testare la similarità tra il target ed \ac{H}. Invece durante le generazioni delle ipotesi intermedie si ha soltanto \ac{H} e quindi il W-Method va eseguito necessariamente su questo \ac{DFA})stimando gli stati dell'altro.\\
Ipotizzando in chiave espositiva che il \ac{DFA} col numero minore di stati sia \ac{H} si procede generando lo \textit{state cover} $C$ su \ac{H} cioè  $C =\{c : \forall q \in Q^{\ac{H}} \:\: \hat{\delta}^{\ac{H}}(q_\epsilon,c)=q\}$ cioè l'insieme di stringhe necessarie per raggiungere ogni stato a partire dallo stato iniziale. Due stati $q_1,q_2$ di \ac{H} sono detti \textit{W-distinguibili} se dato un insieme di stringhe $W \subseteq \Sigma^{*}  \: \:\exists x \in W : ( ( \lambda^{\ac{H}}_{q_{1}}(x) = 1 \land \lambda^{\ac{H}}_{q_{2}}(x) = 0) \lor ( \lambda^{\ac{H}}_{q_{1}}(x) = 0 \land \lambda^{\ac{H}}_{q_{2}}(x) = 1) )$ . W è detto un \textit{characterization set} se tutti gli stati distinti di \ac{H} (essendo \ac{H} minimo tutti gli stati sono distinti) presi a due a due  sono \textit{W-distinguibili}. Definito $k = \norma{A} - \norma{H}$ essere una stima (si parla di stima perchè il target A è ignoto) di quanti stati ha il target in più dell'ipotesi si ha che il \textit{test set} $Y$ è:
\begin{equation*}
Y = C(\{\epsilon\} \cup \Sigma \cup \dots \cup \Sigma^{k+1})W
\end{equation*}

Il difetto di questa tecnica è che la complessità dipende in maniera esponenziale \cite[p. 181]{Chow78} da  $\norma{A} - \norma{H}$ e quando questa differenza di stati diventa grande il metodo è ingestibile e il numero di stringhe generate dal \textit{W-Method} diventa enorme.


\subsection{Generazione dei campioni per SVM}
\label{sub:csvm}
Per effettuare l'addestramento delle \ac{SVM} è necessario creare un \textit{training set}. Anche la dimensione del \textit{training set} e del \textit{test set} è estremamente rilevante per le performances di un classificatore statistico e quindi è necessario scandagliare il comportamento dell'algoritmo al variare della dimensionalità di questi parametri. Attenendosi a quanto fatto nella competizione STAMINA \cite{Stamina10} si crea un \textit{sample set} tramite \textit{random walk}, che fornisce stringhe in maniera equamente bilanciata tra accettanti e rigettanti, sul \ac{DFA} target e da esso si estrapolano due insiemi \textbf{disgiunti}\footnote{Affinchè le performances non siano ottimisticamente biased è necessario che l'addestramento avvenga su un \textit{training set} che non ha elementi in comune con il \textit{test set}} \textit{training set} e un \textit{test set}. In STAMINA il \textit{sample set} è di dimensione 20000 e da esso si estrae un \textit{test set} di dimensione 1500 e dalle rimanenti stringhe si estrae con una procedura che non è rilevante descrivere il \textit{training set} di quattro diverse dimensioni che dipendono da un valore impostato dall'esterno ma grossolanamente si può affermare che le quattro dimensioni del \textit{training set} sono $\{20000,10000,5000,2500\}$. Ricalcando da vicino quanto appena descritto in STAMINA si è creato con \textit{random walk} un insieme di 1500 stringhe da cui si è estratto un insieme di 1000 elementi per il \textit{test set} e 500 per il \textit{training set}. Il metodo implementato per effettuare lo \textit{splitting} (realizza un ''sampling without replacing'') realizza anche la stratificazione (cfr. App. \ref{sub:hol}) e funziona anche nel caso che i campioni non siano equamente bilanciati.
Rispetto a STAMINA il \textit{test set} anzichè 1500 elementi ne ha 1000 perchè è comunque un numero di campioni sufficientemente significativo e perchè per alcuni automi è risultato  complicato generare un numero elevato di campioni con \textit{random walk} come si spiegherà a breve. Per lo stesso motivo il \textit{training set} è molto ridotto rispetto a STAMINA e ciò potrebbe costituire un notevole svantaggio. Un'altra ragione per un \textit{training set} ridotto è pratico dato che SVM$^{light}$ ha dei seri problemi di convergenza quando la dimensione dell'insieme di addestramento diventa dell'ordine di 2000--3000 elementi quindi aumentarne la dimensione potrebbe rendere l'algoritmo estremamente lento. Si puntualizza che la velocità dell'algoritmo di \ac{SVM} di trovare una soluzione dipende non solo da quanti sono in numero i campioni ma anche dagli specifici dati, sia da un punto di vista di contingenza di quest ultimi che dalla difficoltà nel separarli perchè essi riflettono la complessità del linguaggio target che rappresentano cioè più il target è complesso e più è probabile che i dati siano difficili da separare con \ac{SVM}. Da un punto di vista di un'eventuale utilizzazione il limite di 500 campioni non costituisce un limite dato che i campioni in questo caso sono quelli forniti dall'utente e tipicamente non sono un numero ingente, ma ciò ha impedito di testare il comportamento di \ac{ObPA} su \textit{training set} grandi e uniformarsi a quanto fatto nelle varie competiziono di \ac{GI}.  \\ 
 Nella \textit{ideal version} del codice il \textit{setting} per la generazioni dei campioni per l'addestramento è quello appena descritto.
Nella \textit{release version} i campioni non vanno generati su un\ac{DFA} target perchè ignoto ma vanno inseriti dall'esterno. L'utente dovrà provvedere ad inserirli su file rispettando uno specifico formato:  
\begin{equation*}
etichetta \quad simbolo\_alfabeto \quad simbolo\_alfabeto \quad simbolo\_alfabeto \dots
\end{equation*}
Ad esempio se l'alfabeto è $\Sigma = \{0 \: tao \: 2\}$ e la stringa $tao2002tao2$ è accettante, nel file ci dovrà essere una riga siffatta:
\begin{equation*}
1 \quad tao \quad 2 \quad 0 \quad 0 \quad 2 \quad tao \quad 2
\end{equation*}
Il primo e unico 1 è l'etichetta per una stringa accettante, l'etichetta per una stringa rigettante deve essere -1. Inoltre è necessario inserire nel file prima gli esempi positivi e poi a seguire quelli negativi. Sono ammessi duplicati perchè potrebbero essere significativi.\\

 Per alcuni linguaggi del dataset Tomita  sono stati riscontrati dei problemi nella generazione del \textit{sample set} tramite \textit{random walk}. Si ha che \textit{random walk} nella ricerca di campioni positivi effettua un cammino probabilistico nel \ac{DFA}, che si arresta con una probabilità tale da produrre campioni che superano la profondità del \ac{DFA} (cioè di una lunghezza tale da esplorare con buona probabilità tutti gli stati del grafo); ma se il \ac{DFA} ha uno stato pozzo può accadere che molte delle stringhe casuali generate arrivino allo stato pozzo nel quale il cammino casuale termina perchè per ogni simbolo dell'alfabeto da uno stato pozzo si termina ancora nello stesso stato pozzo. In \ac{DFA} piccoli con pochi stati come i Tomita è altamente probabile terminare casualmente in uno stato pozzo e quindi si riescono a  generare solo pochi campioni positivi anche facendo molti tentativi ,infatti per i linguaggi incriminati che sono $L_1,L_2,L_8,L_9,L_{10},L_{12},L_{14},L_{15}$ neanche impostando una soglia altissima del numero massimo di tentativi  da fare  ci si è avvicinati ai 1500 oppure 500 campioni richiesti (la soglia è 600000 ed in alcuni casi come $L_7$ la generazione dei campioni con \textit{random walk} risulta lenta). Allora per i linguaggi suddetti malgrado quanto detto in precedenza (uniformarsi a STAMINA) si è proceduto gioco forza alla generazione casuale dei campioni. \'E importante fare notare che  i campioni positivi dei linguaggi problematici sono stati costruiti casualmente ma sfruttando sia la conoscenza della struttura dell'automa che del linguaggio evitando nella fattispecie i problemi relativi al  \textit{random sampling} per il \textit{test set} precedentemente esposti.  Ad esempio per il linguaggio $L_2$ nel caso si debbano generare $num\_samples$ campioni positivi si estrae un numero casuale tra $0$ e $2*num\_samples$ e il numero estratto indica quante volte consecutivamente andrà ripetuta la sottosequenza  $ba$. Considerazioni analoghe per gli altri linguaggi problematici. La generazione manuale dei campioni per i linguaggi suddetti è relativa solo ai campioni positivi, quelli negativi vengono generati ancora con \textit{random walk} (una versione modificata all'occorrenza) a partire dai campioni casuali positivi generati in precedenza\footnote{\textit{random walk} genera i campioni negativi a partire da quelli positivi effettuando un numero casuale di modifiche su di essi.}.
 
\subsection[Valutazione DFA inferito]{Comparazione di DFA target e DFA inferito da ObPA}
\label{sub:comdfa}
Nella sottosezione \ref{sub:wme} è stato detto che ,nella \textit{ideal version}, quando \ac{ObPA} termina è necessario confrontare il \ac{DFA} target con il \ac{DFA} inferito dall'algoritmo \ac{ObPA}. Il \textit{test set} per effettuare il confronto va creato con il W-Method perchè: rende irrilevante l'eventuale presenza nel \textit{test set} di campioni già usati in fase di addestramento , genera un insieme di campioni estremamente significativo per il confronto, non necessità di un'impostazione manuale del numero di campioni nel \textit{test set} che è automaticamente tornato dal W-Method. Non sarà richiesta neanche la stima del numero di stati del \ac{DFA} target dato che quest ultimo in \textit{ideal version} è noto. Nonostante i pregi evidenziati il W-Method ha originato molti problemi pratici ed è stato necessario provvedere con rimedi ad hoc. Nei seguenti casi non si usa il W-Method per la generazione dei campioni per il confronto:
\begin{enumerate}
\item \label{ite:wm1}Differenza di stati tra \ac{DFA} target e \ac{DFA} inferito maggiore di 10
\item \label{ite:wm2} \textit{Test set} creato dal W-Method troppo grande, maggior di 500000 campioni
\item \label{ite:wm3} \textit{Test set} creato dal W-Method troppo piccolo, minore di 100 campioni
\end{enumerate}
 Nel caso \ref{ite:wm1} a causa della complessità esponenziale del W-Method dipendente dalla differenza del numero di stati tra \ac{DFA} target e \ac{DFA} inferito il W-Method non termina in tempi accettabili. Nel caso \ref{ite:wm2} il W-Method termina ma ritorna un numero eccessivo di campioni che renderebbero eccessivamente lenta la fase successiva in cui si devono calcolare le statistiche sul \textit{test set} (anche se i due \ac{DFA} differiscono per pochi stati, ma hanno un numero elevato di stati il W-Method potrebbe generare un numero considerevole di stringhe; anche per \ac{DFA} piccoli che differiscono per pochi stati ma con un grande alfabeto vengono generate tante stringhe), quindi si è fissata la soglia di 500000 campioni.  Il caso \ref{ite:wm3} deriva principalmente dalla situazione in cui il \ac{DFA} inferito da \ac{ObPA} e il \ac{DFA} target hanno lo stesso numero di stati oppure sono automi piccoli (con pochi stati) che differiscono per pochi stati: in tali situazioni il numero di campioni generati dal W-Method è esiguo.
 
In tutti e tre i casi si passa automaticamente  all'utilizzo di \textit{random walk} (nei casi \ref{ite:wm2} e \ref{ite:wm3} è richiesta l'esecuzione di entrambi gli algoritmi perchè per capire di essere ricaduti in uno dei casi summenzionati e passare all'esecuzione di \textit{random walk} è necessaria la preventiva esecuzione del \textit{W-Method}).  \\
Il \textit{W-Method} va sempre invocato usando come chiamante il \ac{DFA} con meno stati  (e questo può essere sia il \ac{DFA} inferito che il \ac{DFA} target).\\
La comparazione (cioè verificare la rispondenza o meno dei campioni sui due \ac{DFA}) invece avviene usando sempre il \ac{DFA} inferito come ''test'' cioè si deve testare come classifica il \ac{DFA} inferito rispetto al \ac{DFA} target ad esempio si ha un falso positivo quando il \ac{DFA} inferito classifica un campione come positivo e il \ac{DFA} target come negativo.

Quando si rientra in uno dei tre casi e si usa \textit{random walk}, siccome quest ultimo rispetto al \textit{W-Method} può essere meno attendibile, si creano 1500 campioni sia sul \ac{DFA} target che su quello inferito ; si hanno due \textit{test set}  allo scopo di non trascurare aspetti significativi dei due linguaggi.  I campioni  sono bilanciati (\textit{random walk} genera campioni bilanciati)  tuttavia quando si calcolano le statistiche sui due \textit{test set} (cioè le misure, cfr. App. \ref{sub:measure}) in entambi i casi si usa come ''test'' il \ac{DFA} inferito e ad esempio si ha un falso positivo quando il \ac{DFA} target classifica un campione come negativo e il \ac{DFA} inferito da \ac{ObPA} lo classifica come positivo. Inoltre anche se si generano 1500 stringhe bilanciate sul \ac{DFA} inferito con \textit{random walk}, esse possono risultare non bilanciate rispetto al \ac{DFA} target e questo spiega perchè nelle statistiche potrebbe comparire un numero di stringhe positive e negative differente dalla ripartizione dicotomica di 750 positive e 750 negative.\\
Una gestione particolare si è resa necessaria nel caso del Tomita dataset perchè come spiegato   nella sottosezione \ref{sub:csvm} per i linguaggi di Tomita $L_1$,$L_2$,$L_8$,$L_9$,$L_{10}$,$L_{12}$,$L_{14}$,$L_{15}$  \textit{random walk} non riesce a generare i campioni e lo stesso accade in questo contesto e per essi si è dovuto generare i campioni manualmente (alla stregua di quanto fatto in fase di addestramento \ref{sub:csvm}). Inoltre per questi linguaggi di Tomita problematici si generano i 1500 campioni del \textit{test set} solo sul \ac{DFA} target, perchè il \ac{DFA} inferito da \ac{ObPA} potrebbe essere simile al target o molto diverso (il punto è che non lo si sa in anticipo) e quindi \textit{random walk} potrebbe ''impigliarsi'' o meno e comunque non si possono generare le stringhe accettanti manualmente perchè non si conosce il linguaggio corrispondente al \ac{DFA} inferito da \ac{ObPA}.\\

Le misure riportate in uscita (che come appena spiegato in alcuni casi sono duplici perchè relative a due \textit{test set}) sono quasi tutte descritte nell'Appendice \ref{sub:measure} e nella fattispecie sono:
\begin{itemize}
\item TP,FP,TN,TP
\item Campioni positivi e negativi (valutati sul \ac{DFA} target)
\item Accuracy
\item $Precision^{+},Recall^{+},Recall^{-}$
\item F-measure calcolata per i campioni positivi
\item Balanced Classification Rate (BCR) (misura che tiene contemporaneamente conto dei campioni positivi e negativi)
\item MCC(Mattehws correlation coeffient)
\end{itemize}        
Particolare rilevanza ai fini della valutazione come spiegato nell'Appendice \ref{sub:measure} è stata data  alla misura MCC.

Infine si puntualizza che il \textit{W-Method} pressupone due automi canonici per cui sia il \ac{DFA} inferito da \ac{ObPA} che il \ac{DFA} target vanno preventivamente minimizzati.
	  
\subsection[Gen. camp. per EQ]{Generazione dei campioni per un EQ}
\label{sub:ceq}
Per l'effettuazione di un \ac{EQ} approssimata è necessario predisporre un insieme di stringhe (cfr. sottosezione\ref{subsub:eqa}). L'utilizzo del \textit{W-Method} per la generazione dei campioni è una scelta naturale. In questo caso si ha un unico \ac{DFA} cioè l'ipotesi \ac{H} intermedia prodotta da \ac{ObP} e dall'altra parte si ha il classificatore inizialmente creato che approssima il \ac{DFA} target. Il \textit{W-Method} va eseguito su \ac{H} che deve essere preventivamente minimizzato dato che \ac{ObP}, come spiegato nella sottosezione \ref{sub:corret},  assicura che il \ac{DFA} finale sia minimo ma tale proprietà non è garantita per le ipotesi intermedie (a differenza dell'algoritmo $L^{*}$). \ac{ObPA} utilizza il \textit{W-Method} ,per generare le stringhe su cui effettuare un \ac{EQ} approssimata, applicandolo all'ipotesi \ac{H}  ma nel momento in cui , per uno dei tre motivi già esposti nella sottosezione \ref{sub:comdfa}, si è impossibilitati ad utilizzarlo si impiega \textit{random walk} e da quel momento in poi si utilizza \textit{random walk} anche per le altre eventuali ipotesi intermedie \ac{H} dato che è altamente probabile che i problemi in cui si è incorsi al passo corrente siano presenti addirittura amplificati nei successivi \textit{round} dell'algoritmo.  Essendo il numero di stati del target ignoto si utilizza un algoritmo adattivo sul numero di stati dell'ipotesi per effettuarne la previsione: basandosi sulla constatazione che al crescere del numero di stati di \ac{H} la previsione del numero di stati del target deve essere sempre più vicina a $\norma{\ac{H}}$ pena un numero di campioni esorbitante ritornato dal \textit{W-Method} si ha che 
\begin{equation*}
num\_stati\_target = floor(k * \norma{\ac{H}})
\end{equation*}
con k un valore $\in \{7,5,2.5,1.8,1.5\}$ prelevato in maniera corrispondente al superamento dei rispettivi stati di $\norma{\ac{H}} \in \{2,3,6,10,16\}$. Per meglio chiarire si ha che per esempio se $3<=\norma{\ac{H}}<6  \: \: \: k=2.5$.  Inoltre, se  $\norma{\ac{H}}>15 \: \: \: k=1.1$ 
Se le stringhe generate col W-Method sono in numero esiguo si tenta di aumentare la previsione sul numero degli stati del target e verificare se rieseguendo il \textit{W-Method} si riesce ad incrementare il numero di campioni prodotti superando la soglia minima di 100 campioni.

Nel caso si usi \textit{random walk} si cerca di generare 1500 campioni, se non si riesce nell'intento (per motivi analoghi ai linguaggi Tomita) si usa un \textit{test set} ridotto ma nel caso che non vengano creati neanche 100 campioni si ha il lancio di un'eccezione e la terminazione di \ac{ObPA}.

\section{Risultati}
In questa sezione vengono riportati e si analizzano i risultati degli esperimenti condotti. \\
Nel grafico \ref{fig:obpa3tomcla} viene valutato il grado di approssimazione del linguaggio target da parte del classificatore ottenuto tramite \ac{SVM} per quanto riguarda il dataset Tomita. Nel grafico come misura è riportata l'accuracy su un \textit{test set} di 1000 campioni come ampiamente spiegato nella sezione precedente. Sono state prese in considerazione anche altre misure come precision e recall che non sono state riportate in quanto sono coerenti con i risultati positivi trovati per \ac{ObPA}3. Gli esperimenti sono stati condotti per \ac{ObPA}2 ed \ac{ObPA}3 che sono messi a confronto nel grafico \ref{fig:obpa3tomcla} da cui si evince che \ac{ObPA}4 ottiene delle performances quasi sempre migliori nella costruzione del classificatore . \'E importante osservare che sarebbe stato opportuno eseguire più volte lo stesso algoritmo per ciascun linguaggio di Tomita e poi fare una media dei risultati ottenuti per ottenere una misura ancora più affidabile e il più possibile indipendente dalla casualità dello specifico \textit{training set} estratto in fase di addestramento, ma la potenza elaborativa a disposizione non lo ha permesso. \\
L'algoritmo \ac{ObPA}1 ha mostrato delle performances di generalizzazione paragonabili a quelle di \ac{ObPA}2 ma non ne sono stati riportati i risultati perchè per esso si è addestrato il classificatore con un \textit{training set} più piccolo a causa dello spazio dei parametri molto grande di questo algoritmo e della mancanza di potenza computazionale a disposizione.\\ Si precisa che \ac{ObPA}1 \ac{ObPA}2 e \ac{ObPA}3 possono richiedere molto tempo in alcuni frangenti a causa dei problemi di efficienza legati al W-Method o in fase di addestramento con $\ac{SVM}^{light}$ o a causa dell'ipotesi che diventa troppo grande come si chiarirà a breve . Tra i tre l'algoritmo più efficiente si è mostrato essere \ac{ObPA}3 principalmente perchè non deve eseguire una $grid-search()$.\\
La seconda fase di \ac{ObPA} consiste nell'inferire un \ac{DFA}. Si imposta la soglia per il superamento di un' \ac{EQ} approssimata pari a 0.8 (corrispondente al valore di MCC, 0.8 per MCC è equivalente a un valore di accuracy di circa il 90$\%$) \footnote{è resa parametrica e quindi impostabile dall'esterno a un altro valore}. Infine il \ac{DFA} inferito va confrontato con il target e per \ac{ObPA}3 i risultati di questo  confronto sono riportati nel grafico   \ref{fig:obpa3tommat} per il dataset Tomita  ottenendo ottimi risultati. Per $L_1$,$L_2$,$L_5$,$L_6$,$L_{11}$,$L_{12}$,$L_{13}$,$L_{14}$ viene inferito un \ac{DFA} identico al \ac{DFA} target. Per gli altri casi si ottengono comunque ottime performances. Nonostante il \ac{DFA} inferito e il target siano simili come linguaggi per tutto il dataset Tomita per alcuni linguaggi non lo sono nella forma infatti  i \ac{DFA} inferiti per $L_3$,$L_4$,$L_7$,$L_9$ hanno dai 4000 ai 9000 stati.  Il problema probabilmente deriva dal fatto che il classificatore che si addestra approssima soltanto il linguaggio target a meno che non raggiunga un'accuracy del $100\%$ e quindi il classificatore potrebbe rappresentare un linguaggio corrispondente a un \ac{DFA} con un numero di stati enorme o addirittura un linguaggio non regolare. Per questo motivo quando \ac{ObP} cerca di apprendere il linguaggio rappresentato dal classificatore si assiste a un'esplosione nel numero di stati del \ac{DFA} inferito. A suffragare questa tesi vi è il fatto che per $L_3$,$L_4$,$L_7$ tre dei linguaggi per i quali il \ac{DFA} inferito ha un numero di stati enorme il classificatore addestrato era buono ma non perfetto.  Da un punto di vista pratico si ha che la soglia dell'\ac{EQ} non viene superata e l'ipotesi continua a crescere e per gestire  l'evenienza si è provvede fissando una dimensione massima dell'ipotesi oltre la quale fermare l'esecuzione dell'algoritmo per motivi di efficienza.   \ac{ObP} cerca di apprendere il classificatore che è stato precedentemente costruito ma se quest ultimo non approssima bene il \ac{DFA} target \ac{ObP} apprenderà un linguaggio errato. Quindi conditio sine qua per la riuscita dell'algoritmo è l' efficacia del classificatore.\\

Nel grafico \ref{fig:obpa3rancla} sono illustrati i risultati di \ac{ObPA}2 e \ac{ObPA}3 che mettono in evidenza come anche per \ac{ObPA}3 si assiste a una rapida diminuzione delle performances al crescere della complessità del \ac{DFA} target e del suo alfabeto. \\
Facendo un'analisi critica dei risultati si potrebbe concludere che anche il migliore degli algoritmi cioè \ac{ObPA}3 oltre 10 stati e alfabeto 5 non è più efficace. Tuttavia nella fruizione pratica della libreria il target è ignoto dato che è l'oggetto dell'inferenza e occorrerebbe qualche parametro oggettivo per capire se l'inferenza ha avuto buon fine oppure ciò che è stato inferito è a malapena migliore del lancio di una moneta.  Acciochè per \ac{ObPA}3 si può utilizzare il massimo margine trovato. Nel grafico \ref{fig:maracc} che mette in relazione l'accuracy di \ac{ObPA}3 sul random dataset con il margine  si trova conferma di quanto detto. Per \ac{ObPA}2 si può utilizzare come feedback l'accuracy tornata dalla \textit{5-fold-validation} mentre si fa model selection come si evince dal grafico \ref{fig:ob2tom} che confronta i risultati di model  selection e model evaluation (quest ultimi già precedentemente illustrati) per il Dataset Tomita. \\
I confini di funzionamento dell'algoritmo non sono tuttavia netti e delineati, ad esempio sono stati sperimentati dei \ac{DFA} estratti casualmente con la libreria LearnLib (oltre quelli del Random Dataset) di dimensione dell'alfabeto 2 e numero di stati 5 per il quale \ac{ObPA}3 si comportava male ed anche un \ac{DFA} di 47 stati e alfabeto 15 per il quale \ac{ObPA} 3 riesce a creare un classificatore con un'accuracy dell'$88\%$. Un modo empirico anche se privo di fondamento scientifico per rendersi conto  in \textit{release version} di \ac{ObPA} se il classificatore inferito è una buona approssimazione del linguaggio target da scovare è il tempo impiegato da \ac{ObPA} per costruire il classificatore che a sua volta dipende principalmente da quanto è veloce l'algoritmo della libreria $\ac{SVM}^{light}$ nel separare i campioni.\\
Infine nel grafico \ref{fig:varacdimtr} si riporta uno studio sulla variazione dell'accuracy del classificatore al crescere del \textit{training set}. Tuttavia si è scelto di testare un singolo \ac{DFA} di dimensione dell'alfabeto 15 e numero di stati 5 estratto casualmente anzichè uno dei due dataset nella loro interezza per questioni inerenti la sfera della potenza elaborativa a disposizione. 


\definecolor{col1}{RGB}{37,116,169}
%\definecolor{col1}{RGB}{92,151,191}

%QUI ACCURACY DI CLASIIFICATORI PER OBPA2 e OBPA3 PER TOMITA

\begin{figure}
\centering
\begin{tikzpicture}
\pgfplotsset{
every axis legend/.append style={
at={(0.5,1.03)},
anchor=south
},
}
\begin{axis}
[
        width=13cm,
        height=7cm,
        legend columns=4,
        legend style={draw=none},
        %title style={at={(0.5,0)},anchor=north,yshift=-0.1},
        %title={\ac{ObPA}3},
        ticklabel style={font=\tiny},
        %xlabel style={font=\tiny, above},
        %ylabel style={font=\tiny},
        xlabel=\textbf{Tomita Dataset},
        ylabel=\textbf{Accuracy},
        %ylabel style={rotate=-90},
        ymajorgrids=true,
        xtick=data,
        %mark size=2.0pt,
        xtick style={draw=none},
       %,xtick={0,1,...,3}
        xticklabels={$L_1$,$L_2$,$L_3$,$L_4$,$L_5$,$L_6$,$L_7$,$L_8$,$L_9$,$L_{10}$,$L_{11}$,$L_{12}$,$L_{13}$,$L_{14}$,$L_{15}$}
        ]
        
\addplot[very thick, color=col1,mark=*,
                mark options={solid},
                draw opacity=0.9,
                %smooth
                ] coordinates
    {(0,100.00) (1,100.00) (2,79.00) (3,81.20) (4,100.00) (5,100.00) (6,79.00) (7,99.90) (8,99.70) (9,100.00) (10,100.00) (11,100.00) (12,100.00) (13,100.00) (14,99.80)};

\addplot[very thick, color=col1,mark=square,
               draw opacity=0.5,
                mark options={solid},
                %smooth
                ] coordinates
    {(0,66.60) (1,93.00) (2,76.30) (3,97.80) (4,80.00) (5,63.56) (6,97.80) (7,59.43) (8,80.06) (9,62.76) (10,82.70) (11,60.80) (12,51.20) (13,85.14) (14,61.00)};  

\legend{\tiny{ObPA3}, \tiny{ObPA2}}
   
    \begin{comment}
 \addplot[very thick, color=col1,mark=square,
               draw opacity=0.7,
                mark options={solid},
                %smooth
                ] coordinates
    {(0,100.00) (1,100.00) (2,78.43) (3,79.66) (4,100.00) (5,100.00) (6,77.03) (7,100.00) (8,99.80) (9,100.00) (10,100.00) (11,100.00) (12,100.00) (13,100.00) (14,100.00)};  
    
    \addplot[very thick, color=col1,mark=triangle,
               draw opacity=0.5,
                mark options={solid},
                %smooth
                ] coordinates
    {(0,100.00) (1,100.00) (2,80.00) (3,83.80) (4,100.00) (5,100.00) (6,79.80) (7,99.80) (8,99.60) (9,100.00) (10,100.00) (11,100.00) (12,100.00) (13,100.00) (14,99.60)};
    
    \addplot[very thick, color=col1,mark=diamond,
               draw opacity=0.3,
                mark options={solid},
                %smooth
                ] coordinates
    {(0,100.00) (1,100.00) (2,79.59) (3,82.91) (4,100.00) (5,100.00) (6,79.05) (7,99.80) (8,99.60) (9,100.00) (10,100.00) (11,100.00) (12,100.00) (13,100.00) (14,99.60)};
    
    \addplot[very thick, color=col1,mark=x,
               draw opacity=0.1,
                mark options={solid},
                %smooth
                ] coordinates
    {(0,100.00) (1,100.00) (2,78.00) (3,78.60) (4,100.00) (5,100.00) (6,76.20) (7,100.00) (8,99.80) (9,100.00) (10,100.00) (11,100.00) (12,100.00) (13,100.00) (14,100.00)}; 
    \end{comment}
\end{axis}
\end{tikzpicture}

\caption*{Accuracy del classificatore per i Tomita: ObPA2 vs ObPA3}
   \label{fig:obpa3tomcla}
\end{figure}





%QUI ACCURACY CLASSIFICATORE OBPA2 e OBPA3 sui DFA casuali

\begin{figure}
\centering
\begin{tikzpicture}
\pgfplotsset{
every axis legend/.append style={
at={(0.5,1.03)},
anchor=south
},
}
\begin{axis}
[
        width=13cm,
        height=7cm,
        legend columns=4,
        legend style={draw=none},
        %title style={at={(0.5,0)},anchor=north,yshift=-0.1},
        %title={\ac{ObPA}3},
        ticklabel style={font=\tiny},
        %xlabel style={font=\tiny, above},
        %ylabel style={font=\tiny},
        xlabel=\textbf{Random Dataset},
        ylabel=\textbf{Accuracy},
        %ylabel style={rotate=-90},
        ymajorgrids=true,
        xtick=data,
        %mark size=2.0pt,
        xtick style={draw=none},
       %,xtick={0,1,...,3}
        xticklabels={$R_1$,$R_2$,$R_3$,$R_4$,$R_5$,$R_6$,$R_7$,$R_8$,$R_9$,$R_{10}$,$R_{11}$,$R_{12}$,$R_{13}$,$R_{14}$,$R_{15}$,$R_{16}$}
        ]
        
\addplot[very thick, color=col1,mark=*,
                mark options={solid},
                draw opacity=0.9,
                %smooth
                ] coordinates
    {(0,99.70) (1,70.00) (2,52.15) (3,51.00) (4,66.5) (5,58.18) (6,50.00) (7,49.00) (8,60.00) (9,53.10) (10,49.04) (11,50.60) (12,53.00) (13,50.00) (14,50.00) (15,50.30)};

\addplot[very thick, color=col1,mark=square,
               draw opacity=0.5,
                mark options={solid},
                %smooth
                ] coordinates
    {(0,52.00) (1,53.90) (2,56.20) (3,53.9) (4,51.5) (5,49.30) (6,50.90) (7,46.30) (8,61.70) (9,50.55) (10,48.5)  (11,50.90) (12,60.86) (13,58.03) (14,55.3) (15,50)};  

\legend{\tiny{ObPA3}, \tiny{ObPA2}}
   
   
\end{axis}
\end{tikzpicture}

\caption*{Accuracy del classificatore DFA casuali: ObPA2 vs ObPA3}
   \label{fig:obpa3rancla}
\end{figure}




%QUI MATTEWS PER SIMILARITA' TRA TARGET e DFA INFERITO


\begin{figure}
\centering
\begin{tikzpicture}
\pgfplotsset{
every axis legend/.append style={
at={(0.5,1.03)},
anchor=south
},
}
\begin{axis}
[
        width=13cm,
        height=7cm,
        legend columns=4,
        legend style={draw=none},
        %title style={at={(0.5,0)},anchor=north,yshift=-0.1},
        %title={\ac{ObPA}3},
        ticklabel style={font=\tiny},
        %xlabel style={font=\tiny, above},
        %ylabel style={font=\tiny},
        xlabel=\textbf{Tomita Dataset},
        ylabel=\textbf{MCC},
        %ylabel style={rotate=-90},
        ymajorgrids=true,
        xtick=data,
        %mark size=2.0pt,
        xtick style={draw=none},
       %,xtick={0,1,...,3}
        xticklabels={$L_1$,$L_2$,$L_3$,$L_4$,$L_5$,$L_6$,$L_7$,$L_8$,$L_9$,$L_{10}$,$L_{11}$,$L_{12}$,$L_{13}$,$L_{14}$,$L_{15}$}
        ]
        
\addplot[very thick, color=col1,mark=*,
                mark options={solid},
                draw opacity=0.9,
                %smooth
                ] coordinates
    {(0,1.00) (1,1.00) (2,0.54) (2,0.47) (3,0.62) (3,0.49) (4,1) (4,1) (5,1) (5,1) (6,0.61) (6,0.43) (7,1) (8,0.78) (9,1) (10,1) (10,1) (11,1) (12,1) (12,1) (13,1) (14,0.58)};


   

\end{axis}
\end{tikzpicture}

\caption*{Similarità tra target e DFA inferito da ObPA3 con MCC}
   \label{fig:obpa3tommat}
\end{figure}






\begin{figure}
\centering
\begin{tikzpicture}
\pgfplotsset{
every axis legend/.append style={
at={(0.5,1.03)},
anchor=south
},
}
\begin{axis}
[
        width=13cm,
        height=7cm,
        legend columns=4,
        legend style={draw=none},
        %title style={at={(0.5,0)},anchor=north,yshift=-0.1},
        %title={\ac{ObPA}3},
        ticklabel style={font=\tiny},
        %xlabel style={font=\tiny, above},
        %ylabel style={font=\tiny},
        xlabel=\textbf{Random Dataset},
        %ylabel=\textbf{Accuracy},
        %ylabel style={rotate=-90},
        ymajorgrids=true,
        xtick=data,
        %mark size=2.0pt,
        xtick style={draw=none},
       %,xtick={0,1,...,3}
        xticklabels={$R_1$,$R_2$,$R_3$,$R_4$,$R_5$,$R_6$,$R_7$,$R_8$,$R_9$,$R_{10}$,$R_{11}$,$R_{12}$,$R_{13}$,$R_{14}$,$R_{15}$,$R_{16}$}
        ]
        
\addplot[very thick, color=col1,mark=*,
                mark options={solid},
                draw opacity=0.9,
                %smooth
                ] coordinates
    {(0,99.70) (1,70.00) (2,52.15) (3,51.00) (4,66.5) (5,58.18) (6,50.00) (7,49.00) (8,60.00) (9,53.10) (10,49.04) (11,50.60) (12,53.00) (13,50.00) (14,50.00) (15,50.30)};

\addplot[very thick, color=col1,mark=*,
                mark options={solid},
                draw opacity=0.5,
                %smooth
                ] coordinates
{(0,7.06) (1,2.78) (2,1.71) (3,1.36)  (4,1.68) (5,1.62) (6,1.59) (7,1.54)  (8,2.64) (9,1.61) (10,1.58) (11,1.55) (12,1.74) (13,1.54) (14,1.6) (15,1.30)};

\legend{\tiny{ObPA3}, \tiny{Margine}}
   
   
\end{axis}
\end{tikzpicture}

\caption*{Correlazione tra Accuracy del classificatore e Margine}
   \label{fig:maracc}
\end{figure}











\begin{figure}
\centering
\begin{tikzpicture}
\pgfplotsset{
every axis legend/.append style={
at={(0.5,1.03)},
anchor=south
},
}
\begin{axis}
[
        width=13cm,
        height=7cm,
        legend columns=4,
        legend style={draw=none},
        %title style={at={(0.5,0)},anchor=north,yshift=-0.1},
        %title={\ac{ObPA}3},
        ticklabel style={font=\tiny},
        %xlabel style={font=\tiny, above},
        %ylabel style={font=\tiny},
        xlabel=\textbf{Tomita Dataset},
        ylabel=\textbf{Accuracy},
        %ylabel style={rotate=-90},
        ymajorgrids=true,
        xtick=data,
        %mark size=2.0pt,
        xtick style={draw=none},
       %,xtick={0,1,...,3}
        xticklabels={$L_1$,$L_2$,$L_3$,$L_4$,$L_5$,$L_6$,$L_7$,$L_8$,$L_9$,$L_{10}$,$L_{11}$,$L_{12}$,$L_{13}$,$L_{14}$,$L_{15}$}
        ]
        


\addplot[very thick, color=col1,mark=square,
               draw opacity=0.9,
                mark options={solid},
                %smooth
                ] coordinates
    {(0,66.00) (1,93.00) (2,76.30) (3,88.39) (4,80.00) (5,63.56) (6,97.80) (7,59.43) (8,80.06) (9,62.76) (10,82.70) (11,60.80) (12,51.20) (13,85.14) (14,61.00)};  

\addplot[very thick, color=col1,mark=*,
                mark options={solid},
                draw opacity=0.5,
                %smooth
                ] coordinates
    {(0,66.6) (1,92.00) (2,79.00) (3,87.80) (4,82.40) (5,64.56) (6,98.00) (7,63.00) (8,78.8) (9,67.6) (10,81.4) (11,54.00) (12,49.6) (13,80.60) (13,85.14) (14,57.20)};

\legend{\tiny{M. ev.}, \tiny{5fcv}}
   
    
\end{axis}
\end{tikzpicture}

\caption*{Confronto Accuracy Model Selection e Model Evaluation su  Tomita dataset per ObPA2 }
   \label{fig:ob2tom}
\end{figure}





\begin{figure}
\centering
\begin{tikzpicture}
\pgfplotsset{
every axis legend/.append style={
at={(0.5,1.03)},
anchor=south
},
}
\begin{axis}
[
        width=13cm,
        height=7cm,
        legend columns=4,
        legend style={draw=none},
        %title style={at={(0.5,0)},anchor=north,yshift=-0.1},
        %title={\ac{ObPA}3},
        ticklabel style={font=\tiny},
        %xlabel style={font=\tiny, above},
        %ylabel style={font=\tiny},
        xlabel=\textbf{Dimensione tr. set},
        ylabel=\textbf{Accuracy},
        %ylabel style={rotate=-90},
        ymajorgrids=true,
        xtick=data,
        %mark size=2.0pt,
        xtick style={draw=none},
       %,xtick={0,1,...,3}
        xticklabels={100,250,500}
        ]
        


\addplot[very thick, color=col1,mark=square,
               draw opacity=0.9,
                mark options={solid},
                %smooth
                ] coordinates
    {(0,56.2) (1,59.5) (2,65.8)};  



   
    
\end{axis}
\end{tikzpicture}

\caption*{Confronto Accuracy Model Selection e Model Evaluation su  Tomita dataset per ObPA2 }
   \label{fig:varacdimtr}
\end{figure}



