%!TEX encoding = UTF-8 Unicode
%!TEX root = ./../main.tex
%!TEX TS-program = xelatex

\chapter*{Introduzione} % Introduction chapter title
\label{cap:intro}

Un sistema intelligente è caratterizzato dalla capacità di apprendere in modo auto-
matico, la quale a sua volta presuppone la capacità sia di rappresentare la conoscenza
nota a priori sia di inferirne di nuova. Le tecniche di \textit{estrazione di conoscenza} oggetto di studio  in questa sede riguardano l'apprendimento induttivo di linguaggi formali. L’induzione è un procedimento che elabora informazioni parziali riguardanti le proprietà di un insieme, fornendo una generalizzazione, cioè estendendo l’insieme su cui le proprietà valgono. Questo procedimento in generale non è logicamente giustificato, e di conseguenza non è certo che l’informazione fornita in uscita sia vera. All’interno degli studi sull’induzione nasce l’inferenza grammaticale, che si occupa di studiare le modalità con cui può essere individuato un linguaggio formale, quando è conosciuto un insieme di stringhe che appartengono ad un linguaggio sconosciuto e, eventualmente, un insieme di stringhe che non appartengono al linguaggio. Supponiamo che una sorgente di informazioni fornisca delle stringhe binarie: 
\begin{equation*}
    01, 0101, 010101, \dots
\end{equation*}
Ci si può domandare se c’è una regola formale con la quale la sorgente genera le stringhe, se eventualmente questa regola sia individuabile guardando solo l’insieme delle stringhe, e quali siano i fattori che influenzano l’identificabilità della regola. L’inferenza grammaticale cerca di trovare risposte a queste domande, nell’ipotesi che esiste una regola con cui le stringhe sono state create, e che si tratti di una grammatica generativa di Chomsky. \\
Nella fattispecie, la classe dei linguaggi oggetto di studio per la presente tesi è quella dei linguaggi regolari e si parla pertanto più specificamente di \textit{Inferenza Induttiva Regolare} (IIR), i cui limiti teorici sono stati messi in luce dal lavoro di Gold \cite{Gold67}. Gli algoritmi della letteratura iniziale sull’argomento riconducevano l’apprendimento ad una ricerca euristica in un spazio rappresentato come un grafo contenente gli automi consistenti con i campioni forniti in cui il modello,inizialmente iperspecializzato, viene progressivamente generalizzato. Tale approccio va sotto il nome di \textit{passive learning} ed è caratterizzato da un’inevitabile esplosione combinatoria che ne rende la complessità ingestibile a meno di non sacrificare le garanzie teoriche di terminazione e ottimalità o di stringenti requisiti sui campioni in ingresso.


Nella presente tesi si è quindi scelto di seguire un approccio proposto nella letteratura più recente, duale rispetto al precedente, secondo cui un modello, inizialmente molto generale e quindi poco accurato, viene progressivamente specializzato per rappresentare con precisione i dati forniti. Questo paradigma, noto come \textit{active learning}, presuppone l'esistenza di un \textit{oracolo} che guida l'apprendimento rispondendo ad alcuni tipi di query sottopostegli attivamente dal sistema che cerca di inferire il modello. La base teorica del paradigma è stata fornita dagli studi di Angluin \cite{Angluin87} che stabiliscono che l'oracolo debba appartenere alla classe dei cosiddetti Minimally Adequate Teacher (MAT) che, per garantire l'abilità di fornire risposte utili ai principali tipi di query considerate, richiede la conoscenza preliminare dell'automa oggetto d'inferenza.
Questo è un requisito molto forte e fin troppo stringente, che limita l'utilizzo in contesti reali dell'inferenza induttiva regolare declinata nell'accezione dell'\textit{active learning}.

Il lavoro in questa tesi nasce con l'intenzione di indagare lo scenario nel quale il tradizionale oracolo è sostituito con una sua approssimazione mediante un classificatore statistico costruito a partire da esempi positivi e negativi del linguaggio target nell'ottica di permetterne un utilizzo nelle applicazioni reali. L'obiettivo è quello di tracciare un parallelo tra i modelli ottenibili seguendo il paradigma della teoria dell'apprendimento statistico, Statistical Learning Theory (SLT), e quelli formulabili algoritmicamente nell'ambito dell'inferenza grammaticale con \textit{active learning} e di verificare sperimentalmente se l'uso combinato possa condurre al superamento dei limiti di entrambi ossia rispettivamente un modello poco significativo per i dati di partenza e il requisito di un oracolo onnisciente. In altre parole, si vuole costruire per i campioni dati un modello strutturale, da usare in luogo dell'oracolo in modo da superarne i requisiti stringenti.  Il modello statistico prescelto per affrontare il delineato problema di classificazione binaria è stato quello delle Support Vector Machines (SVM) perchè rappresentano un modello molto potente. Inoltre malgrado siano state proposte in letteratura delle loro applicazioni nel contesto dei linguaggi formali esse non sono state contestualizzate nell’ambito dell’inferenza induttiva regolare mediante \textit{active learning} oppure erano limitate all'apprendimento di specifiche classi di linguaggi sottoinsiemi di quelli regolari.

Al fine di valutare la correttezza della soluzione ottenuta, durante il lavoro di tesi si è progettata un'implementazione in linguaggio C++11, integrando il codice nella preesistente libreria di passive learning Gi-learning \cite{Cot16}. L'implementazione è stata testata sperimentalmente inizialmente su una nota classe di automi che rappresentano linguaggi semplici, ovvero i Tomita \cite{Tomita82, Dupont94}, ottenendo ottimi risultati paragonabili al caso ideale.
Infine le performance e la precisione dei modelli ottenuti dall'approccio qui proposto sono state vagliate su data set di automi estratti casualmente, la cui complessità è paragonabile ai sistemi da apprendere nei casi pratici. I risultati ottenuti rivelano che all'aumentare della complessità del target si ha un progressivo decadimento del grado di approssimazione ed è quindi possibile concludere che un livello di fiducia alto sull'utilizzo dell'algoritmo è ottenibile solo fino ad un certo livello di complessità del target.

Il lavoro qui esposto si divide in cinque parti. Nel primo capitolo si parlerà dell'inferenza induttiva, e riferendosi alla classificazione proposta in \cite{Mic86a}, si inquadrerà questo meccanismo nel complesso meccanismo dell'apprendimento.
Inoltre, dopo avere messo a confronto l'induzione con la deduzione e l'abduzione verranno passati in rassegna le peculiarità del processo induttivo.
Nel secondo capitolo si definirà l'inferenza induttiva grammaticale e saranno scandagliati brevemente i risultati teorici e i limiti dell'\ac{IIR}. Inoltre si descriverà brevemente il \textit{Passive Learning} tecnica duale all' \textit{Active Learning}. Infine sarà presentato brevemente il paradigma dell'\textit{Active Learning} e sarà introdotto e approfondito L* \cite{Angluin87} che può essere considerato il capostipite degli algoritmi di \textit{active learning}.
Nel terzo capitolo verrà esposto in maniera dettagliata la ratio che muove uno dei più efficienti algoritmi di \textit{active learning}:l'\ac{ObP} . Inoltre verranno riportate le scelte discostanti dal riferimento principale dell'algoritmo \cite{Howar12} e le motivazioni.
Il quarto capitolo è il cuore della tesi dove sarà descritto in dettaglio il lavoro  svolto per costruire l'oracolo approssimato e il suo utilizzo concreto all'interno del prescelto algoritmo di \textit{active learning} \ac{ObP}.
Nel quinto capitolo si descriveranno criticamente i risultati sui test eseguiti sul programma al fine di valutarne le prestazioni sia in termini di accuracy del classificatore ottenuto che in termini di similarità tra il \ac{DFA} inferito e il \ac{DFA} target. Inoltre si esaminerà come e quando è possibile variare alcuni parametri dell'algoritmo al fine di migliorarne le prestazioni e in quali contesti (complessità del linguaggio target,numero di esempi del linguaggio da apprendere) è possibile avere un livello di fiducia alto sull'utilizzo dell'algoritmo. 
